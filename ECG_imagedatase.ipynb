{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c624664a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image, ImageOps, ImageFilter\n",
        "\n",
        "# import imutils\n",
        "# import itertools\n",
        "# import shutil\n",
        "# import random\n",
        "# import glob\n",
        "\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "%matplotlib inline"
      ],
      "id": "c624664a"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAk-eAdE2FO1",
        "outputId": "a08fe825-2304-4ea4-cfa4-3425f9939545"
      },
      "id": "DAk-eAdE2FO1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02026858"
      },
      "source": [
        "### Processing Covid19 Patients ECG images"
      ],
      "id": "02026858"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8d084ee"
      },
      "outputs": [],
      "source": [
        "def gammaCorrection(src, gamma):\n",
        "    invGamma = 1 / gamma\n",
        " \n",
        "    table = [((i / 255) ** invGamma) * 255 for i in range(256)]\n",
        "    table = np.array(table, np.uint8)\n",
        " \n",
        "    return cv2.LUT(src, table)"
      ],
      "id": "a8d084ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1IfsP2kob8Xg",
        "outputId": "8d61b4da-3f6c-4623-c2ae-56e83ccbb015"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "pwd"
      ],
      "id": "1IfsP2kob8Xg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fa32179",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "main_path = \"C:\\\\Users\\\\anant\\\\jupyterBooks\\\\LectureNotebooks\\\\2022W\\\\AML_2404_LAB\\\\data1\"\n",
        "\n",
        "main_path = '/content/drive/My Drive/second sem/lab/AIML lab]/Files/working'\n",
        "\n",
        "for foldername in os.listdir(main_path): # looping over the different class folder\n",
        "    \n",
        "    folder = main_path+\"/\"+foldername+\"/\"\n",
        "    Copy_to_path = folder+\"/processed/\"\n",
        "\n",
        "    for index, filename in enumerate(os.listdir(folder)): # retrieving the image files in particular folder\n",
        "        \n",
        "        if filename != 'processed':\n",
        "            \n",
        "            image = cv2.imread(folder+filename, cv2.IMREAD_GRAYSCALE) # grayscale\n",
        "\n",
        "            enhance = cv2.equalizeHist(image) # equalize histogram used to enchance the lines\n",
        "\n",
        "            thrsh = cv2.adaptiveThreshold(enhance,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,41,21) \n",
        "\n",
        "            contrs, _ = cv2.findContours(thrsh.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) # using threshold to get the contours\n",
        "            contrs = list(contrs)\n",
        "\n",
        "            c = max(contrs, key = cv2.contourArea) # getting the largest contours that is the largest shape ( image boundary )\n",
        "\n",
        "            print(c.shape)\n",
        "            if c.shape[0] <= 4:            \n",
        "\n",
        "                contrs.remove(max(contrs, key = cv2.contourArea)) # removing the frame\n",
        "\n",
        "                c = max(contrs, key = cv2.contourArea) # again getting the largest frame that is the pulse frame\n",
        "\n",
        "                x,y,w,h = cv2.boundingRect(c) # getting the co-ordinates\n",
        "\n",
        "\n",
        "                rect = image[y:y+h, x:x+w] # cropping the frame\n",
        "\n",
        "                cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),10) # drawing rectangle with the co-ordinates\n",
        "\n",
        "                gamma_corrected = gammaCorrection(rect,3) # gamma correction\n",
        "\n",
        "                (thresh, im_bw) = cv2.threshold(gamma_corrected, 50, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) # threshold is increased\n",
        "\n",
        "                im_bw_resize = cv2.resize(im_bw,(720, 576)) # resizing the image to 256\n",
        "                img = Image.fromarray(im_bw_resize)\n",
        "                print(filename, \" \", index)\n",
        "                img.save(Copy_to_path+f'{foldername}_{index}.jpg', 'JPEG')\n",
        "        else:\n",
        "            pass"
      ],
      "id": "9fa32179"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e45595ff"
      },
      "source": [
        "### Data Augmentation\n"
      ],
      "id": "e45595ff"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1043930a"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array"
      ],
      "id": "1043930a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02e7a7d4",
        "outputId": "e3aadb9d-71cd-4f86-d9d9-02d4d7f52ad6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\jupyterBooks\\LectureNotebooks\\2022W\\AML_2404_LAB\\data1\\augmented\\abnormalHR\\\n",
            "538\n",
            "batch size for abnormalHR category is 4\n",
            "C:\\Users\\anant\\jupyterBooks\\LectureNotebooks\\2022W\\AML_2404_LAB\\data1\\augmented\\covid19\\\n",
            "250\n",
            "batch size for covid19 category is 8\n",
            "C:\\Users\\anant\\jupyterBooks\\LectureNotebooks\\2022W\\AML_2404_LAB\\data1\\augmented\\historyMI\\\n",
            "199\n",
            "batch size for historyMI category is 8\n",
            "C:\\Users\\anant\\jupyterBooks\\LectureNotebooks\\2022W\\AML_2404_LAB\\data1\\augmented\\miPatients\\\n",
            "72\n",
            "batch size for miPatients category is 8\n",
            "C:\\Users\\anant\\jupyterBooks\\LectureNotebooks\\2022W\\AML_2404_LAB\\data1\\augmented\\normal\\\n",
            "854\n",
            "batch size for normal category is 2\n"
          ]
        }
      ],
      "source": [
        "main_path = \"C:\\\\Users\\\\anant\\\\jupyterBooks\\\\LectureNotebooks\\\\2022W\\\\AML_2404_LAB\\\\data1\"\n",
        "augmented_path = \"C:\\\\Users\\\\anant\\\\jupyterBooks\\\\LectureNotebooks\\\\2022W\\\\AML_2404_LAB\\\\data1\\\\augmented\"\n",
        "\n",
        "data_gen_args = dict(\n",
        "                     width_shift_range=0.1,\n",
        "                     height_shift_range=0.1,\n",
        "                     zoom_range=0.2,\n",
        "                     fill_mode='constant',\n",
        "                     cval=255\n",
        "                    )\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "for foldername in os.listdir(main_path): # looping over the different class folder\n",
        "    if foldername != 'augmented':\n",
        "        \n",
        "        folder = main_path+\"\\\\\"+foldername+\"\\\\processed\\\\\"\n",
        "\n",
        "        Copy_to_path = augmented_path+'\\\\'+foldername+'\\\\'\n",
        "        print(Copy_to_path)\n",
        "\n",
        "    #     determining the files count in each category\n",
        "    #     we want 7500 images in final dataset\n",
        "    #     we have five categories\n",
        "    #     so we need 1500 images in each category\n",
        "        files_count = os.listdir(folder) \n",
        "        print(len(files_count))\n",
        "\n",
        "        total_image_present = len(files_count)\n",
        "        img_batch_size = round(2000/total_image_present)\n",
        "        if img_batch_size > 8 :\n",
        "            img_batch_size = 8\n",
        "\n",
        "        print(f\"batch size for {foldername} category is {img_batch_size}\")\n",
        "        file_count = 0\n",
        "        for filename in os.listdir(folder): # retrieving the image files in particular folder\n",
        "\n",
        "            img = Image.open(folder+filename)\n",
        "            \n",
        "            file_count += 1\n",
        "            #PIL images into NumPy arrays\n",
        "            array = img_to_array(img)\n",
        "            reshaped_np_arr = array.reshape((1,)+array.shape)\n",
        "            count = 0\n",
        "\n",
        "    #             generating the augmentation of images\n",
        "            for batch in image_datagen.flow(\n",
        "                reshaped_np_arr,\n",
        "                batch_size=1,\n",
        "                save_to_dir=Copy_to_path,\n",
        "                save_prefix = foldername+f'{file_count}',\n",
        "                save_format='jpeg',\n",
        "                seed=20\n",
        "            ):\n",
        "\n",
        "                count += 1\n",
        "                if count == img_batch_size:\n",
        "                    break\n",
        "                    \n",
        "                            \n",
        "    else:\n",
        "        pass"
      ],
      "id": "02e7a7d4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bfe0655"
      },
      "source": [
        "### Test Train Split of all classes"
      ],
      "id": "5bfe0655"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7272e4b",
        "outputId": "a30f7bbf-9f4b-48c4-c177-3bc2e9f675fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install split-folders"
      ],
      "id": "c7272e4b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5359086f"
      },
      "outputs": [],
      "source": [
        "import splitfolders"
      ],
      "id": "5359086f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6c44ebc0"
      },
      "outputs": [],
      "source": [
        "augmented_folder = \"C:\\\\Users\\\\anant\\\\jupyterBooks\\\\LectureNotebooks\\\\2022W\\\\AML_2404_LAB\\\\data1\\\\augmented\"\n",
        "output_folder = \"C:\\\\Users\\\\anant\\\\jupyterBooks\\\\LectureNotebooks\\\\2022W\\\\AML_2404_LAB\\\\data1\\\\inputImages\""
      ],
      "id": "6c44ebc0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7a20bd9",
        "outputId": "b1ad32c9-90a1-4115-846d-8c4ade9e82c1",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 8032 files [00:05, 1482.88 files/s]\n"
          ]
        }
      ],
      "source": [
        "splitfolders.ratio(augmented_folder, output=output_folder,\n",
        "    seed=28, ratio=(.75, .25), group_prefix=None, move=False)"
      ],
      "id": "b7a20bd9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "848babe1"
      },
      "source": [
        "# Reading the Test and Val images"
      ],
      "id": "848babe1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9f8e1c24"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ],
      "id": "9f8e1c24"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JA9E_6iBf1Z4",
        "outputId": "eedf329d-4ea1-4e34-8bfe-23eb98b25902"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Mounting google drive to read, write data\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "id": "JA9E_6iBf1Z4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abf32d95"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow-gpu"
      ],
      "id": "abf32d95"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c5fbcac"
      },
      "source": [
        "##### Reading Training Data using keras"
      ],
      "id": "5c5fbcac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCraY3iYggJZ"
      },
      "outputs": [],
      "source": [
        "train_folder = \"/content/drive/My Drive/second sem/lab/data/inputImages/train\""
      ],
      "id": "uCraY3iYggJZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46b0658b",
        "outputId": "9c59e85b-6f87-4d23-b50d-2b768ba5f92f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6024 files belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "training_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    train_folder, \n",
        "    # labels='inferred', \n",
        "    # label_mode='int',\n",
        "    color_mode='grayscale',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=False, seed=11,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    follow_links=False\n",
        ")"
      ],
      "id": "46b0658b"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "for images, labels in training_ds.take(1):  # only take first element of dataset\n",
        "    numpy_images = images.numpy()\n",
        "    numpy_labels = labels.numpy()"
      ],
      "metadata": {
        "id": "TTFKf80qdVAG"
      },
      "id": "TTFKf80qdVAG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7HrlNEnh8wX",
        "outputId": "06c68c3b-785f-4208-8f17-23c6b51d52e1"
      },
      "id": "e7HrlNEnh8wX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GINIf67wJGii"
      },
      "outputs": [],
      "source": [
        "images, labels = tuple(zip(*training_ds))"
      ],
      "id": "GINIf67wJGii"
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJfXW82wgLqQ",
        "outputId": "c09cf131-218a-4491-81fd-95e68df982b1"
      },
      "id": "aJfXW82wgLqQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "        2, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
              "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>,\n",
              " <tf.Tensor: shape=(8,), dtype=int32, numpy=array([4, 4, 4, 4, 4, 4, 4, 4], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6cb431f"
      },
      "source": [
        "##### Reading Test/val Data using keras"
      ],
      "id": "e6cb431f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vksW4KZhhDL7"
      },
      "outputs": [],
      "source": [
        "val_folder = \"/content/drive/My Drive/second sem/lab/data/inputImages/val\""
      ],
      "id": "vksW4KZhhDL7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5fbdbca2",
        "outputId": "15b4fcdb-8613-4b2e-879c-becbd41ef478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2008 files belonging to 5 classes.\n"
          ]
        }
      ],
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    val_folder, \n",
        "    labels='inferred', \n",
        "    label_mode='int',\n",
        "    color_mode='grayscale',\n",
        "    batch_size=32,\n",
        "    image_size=(224, 224),\n",
        "    shuffle=False, seed=11,\n",
        "    validation_split=None,\n",
        "    subset=None,\n",
        "    follow_links=False\n",
        ")"
      ],
      "id": "5fbdbca2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIg23xpsKstI"
      },
      "outputs": [],
      "source": [
        "from keras.layers import *"
      ],
      "id": "YIg23xpsKstI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "832ef126"
      },
      "source": [
        "# Model Creation and training"
      ],
      "id": "832ef126"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model -1 (Epochs incomplete)**"
      ],
      "metadata": {
        "id": "xPf3TLyGZ3_1"
      },
      "id": "xPf3TLyGZ3_1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dORFtA_H8Csv"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Convolution2D, Flatten, Dropout,MaxPooling2D,Conv2D,MaxPool2D\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import BatchNormalization\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3),padding=\"same\", activation=\"relu\",input_shape=(224,224,1)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3),\n",
        "padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3),\n",
        "padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3),\n",
        "padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3),\n",
        "padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3),\n",
        "padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3),\n",
        "padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3),\n",
        "padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3),\n",
        "padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3),\n",
        "padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3),\n",
        "padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "# model.add(Conv2D(filters = 64, kernel_size = (5,5), activation ='relu',input_shape=(224,224,1)))\n",
        "# model.add(BatchNormalization(axis=3))\n",
        "# model.add(Conv2D(filters = 64, kernel_size = (5,5), activation ='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(BatchNormalization(axis=3))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Conv2D(filters = 128, kernel_size = (5,5), activation ='relu'))\n",
        "# model.add(BatchNormalization(axis=3))\n",
        "# model.add(Conv2D(filters = 128, kernel_size = (5,5), activation ='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(BatchNormalization(axis=3))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "# model.add(Conv2D(filters = 256, kernel_size = (5,5), activation ='relu'))\n",
        "# model.add(BatchNormalization(axis=3))\n",
        "# model.add(Conv2D(filters = 256, kernel_size = (5,5), activation ='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "# model.add(BatchNormalization(axis=3))\n",
        "# model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "\n",
        "# model.add(Dense(256, activation = \"relu\")) #Fully connected layer\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# model.add(Dense(60, activation = \"relu\")) #Fully connected layer\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(5, activation = \"softmax\")) #Classification layer or output layer\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# model.summary()"
      ],
      "id": "dORFtA_H8Csv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtEUItCNvxKp",
        "outputId": "c286b348-3329-4688-cb12-0bc14776d57d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 224, 224, 128)     1280      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 224, 224, 128)     147584    \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 112, 112, 128)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 112, 112, 256)     295168    \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 112, 112, 256)     590080    \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 112, 112, 256)     590080    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 56, 56, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 56, 56, 256)       0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 56, 56, 512)       1180160   \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 56, 56, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 56, 56, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 28, 28, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 28, 28, 512)       0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              411045888 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              16781312  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 20485     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 442,451,077\n",
            "Trainable params: 442,451,077\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ],
      "id": "NtEUItCNvxKp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "wdHBVZmr8CyB",
        "outputId": "6c92efd7-25f0-4d29-ee6e-bdce2324aff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "189/189 [==============================] - 2858s 15s/step - loss: 117345353728.0000 - accuracy: 0.8556 - val_loss: 14.4313 - val_accuracy: 0.2126\n",
            "Epoch 2/10\n",
            "189/189 [==============================] - 2837s 15s/step - loss: 1.7948 - accuracy: 0.4563 - val_loss: 2.0438 - val_accuracy: 0.2126\n",
            "Epoch 3/10\n",
            "189/189 [==============================] - 2828s 15s/step - loss: 1.9103 - accuracy: 0.0810 - val_loss: 1.6275 - val_accuracy: 0.1982\n",
            "Epoch 4/10\n",
            " 47/189 [======>.......................] - ETA: 33:34 - loss: 1.6415 - accuracy: 0.2553"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-2fc0efbe7a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m           \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(training_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=10,\n",
        "          verbose=1\n",
        ")"
      ],
      "id": "wdHBVZmr8CyB"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model -2 - Main model**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6yR-iVYjYVTs"
      },
      "id": "6yR-iVYjYVTs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LfoxRTl8C3d",
        "outputId": "b0e99153-d4f9-44a2-e3ce-c801f1f3dfd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_11 (Conv2D)          (None, 224, 224, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 112, 112, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 112, 112, 32)      9248      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 56, 56, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 56, 56, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 28, 28, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 28, 28, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 50176)             0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               6422656   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,451,365\n",
            "Trainable params: 6,451,365\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189/189 [==============================] - 86s 451ms/step - loss: 21.0057 - accuracy: 0.5940 - val_loss: 62.2835 - val_accuracy: 0.2126\n",
            "Epoch 2/500\n",
            "189/189 [==============================] - 62s 325ms/step - loss: 19.6423 - accuracy: 0.5146 - val_loss: 38.5683 - val_accuracy: 0.2126\n",
            "Epoch 3/500\n",
            "189/189 [==============================] - 62s 327ms/step - loss: 16.1386 - accuracy: 0.4892 - val_loss: 26.8234 - val_accuracy: 0.2126\n",
            "Epoch 4/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 13.8148 - accuracy: 0.4487 - val_loss: 19.5075 - val_accuracy: 0.2126\n",
            "Epoch 5/500\n",
            "189/189 [==============================] - 62s 327ms/step - loss: 12.3808 - accuracy: 0.4162 - val_loss: 15.3826 - val_accuracy: 0.2126\n",
            "Epoch 6/500\n",
            "189/189 [==============================] - 63s 331ms/step - loss: 10.9282 - accuracy: 0.3758 - val_loss: 12.0883 - val_accuracy: 0.2126\n",
            "Epoch 7/500\n",
            "189/189 [==============================] - 62s 329ms/step - loss: 9.5074 - accuracy: 0.3501 - val_loss: 9.3406 - val_accuracy: 0.2126\n",
            "Epoch 8/500\n",
            "189/189 [==============================] - 62s 327ms/step - loss: 8.7154 - accuracy: 0.3156 - val_loss: 7.1148 - val_accuracy: 0.2131\n",
            "Epoch 9/500\n",
            "189/189 [==============================] - 61s 325ms/step - loss: 7.8258 - accuracy: 0.3011 - val_loss: 5.5832 - val_accuracy: 0.2131\n",
            "Epoch 10/500\n",
            "189/189 [==============================] - 62s 327ms/step - loss: 6.8135 - accuracy: 0.2726 - val_loss: 4.8092 - val_accuracy: 0.2131\n",
            "Epoch 11/500\n",
            "189/189 [==============================] - 62s 330ms/step - loss: 6.0410 - accuracy: 0.2653 - val_loss: 4.6750 - val_accuracy: 0.2126\n",
            "Epoch 12/500\n",
            "189/189 [==============================] - 62s 328ms/step - loss: 5.5812 - accuracy: 0.2440 - val_loss: 4.4033 - val_accuracy: 0.2126\n",
            "Epoch 13/500\n",
            "189/189 [==============================] - 63s 332ms/step - loss: 5.2079 - accuracy: 0.2507 - val_loss: 3.9141 - val_accuracy: 0.2136\n",
            "Epoch 14/500\n",
            "189/189 [==============================] - 62s 331ms/step - loss: 4.8092 - accuracy: 0.2442 - val_loss: 3.9662 - val_accuracy: 0.2126\n",
            "Epoch 15/500\n",
            "189/189 [==============================] - 62s 330ms/step - loss: 4.1128 - accuracy: 0.2379 - val_loss: 2.5530 - val_accuracy: 0.2136\n",
            "Epoch 16/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 2.8862 - accuracy: 0.2077 - val_loss: 1.6095 - val_accuracy: 0.2679\n",
            "Epoch 17/500\n",
            "189/189 [==============================] - 63s 331ms/step - loss: 2.0816 - accuracy: 0.2090 - val_loss: 1.6094 - val_accuracy: 0.2684\n",
            "Epoch 18/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 1.8152 - accuracy: 0.2369 - val_loss: 1.6094 - val_accuracy: 0.2684\n",
            "Epoch 19/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 1.7464 - accuracy: 0.2442 - val_loss: 1.6094 - val_accuracy: 0.2684\n",
            "Epoch 20/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 1.7171 - accuracy: 0.2483 - val_loss: 1.6094 - val_accuracy: 0.2684\n",
            "Epoch 21/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 1.6750 - accuracy: 0.2558 - val_loss: 1.6094 - val_accuracy: 0.2684\n",
            "Epoch 22/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 1.6649 - accuracy: 0.2462 - val_loss: 1.6094 - val_accuracy: 0.2684\n",
            "Epoch 23/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 1.6482 - accuracy: 0.2644 - val_loss: 1.6093 - val_accuracy: 0.2684\n",
            "Epoch 24/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 1.6439 - accuracy: 0.2641 - val_loss: 1.6093 - val_accuracy: 0.2684\n",
            "Epoch 25/500\n",
            "189/189 [==============================] - 62s 330ms/step - loss: 1.6408 - accuracy: 0.2623 - val_loss: 1.6093 - val_accuracy: 0.2684\n",
            "Epoch 26/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 1.6341 - accuracy: 0.2605 - val_loss: 1.6093 - val_accuracy: 0.2684\n",
            "Epoch 27/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 1.6254 - accuracy: 0.2633 - val_loss: 1.6093 - val_accuracy: 0.2684\n",
            "Epoch 28/500\n",
            "189/189 [==============================] - 62s 329ms/step - loss: 1.6188 - accuracy: 0.2636 - val_loss: 1.6093 - val_accuracy: 0.2684\n",
            "Epoch 29/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 1.6184 - accuracy: 0.2625 - val_loss: 1.6093 - val_accuracy: 0.2684\n",
            "Epoch 30/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 1.6248 - accuracy: 0.2568 - val_loss: 1.6092 - val_accuracy: 0.2684\n",
            "Epoch 31/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 1.6190 - accuracy: 0.2643 - val_loss: 1.6092 - val_accuracy: 0.2684\n",
            "Epoch 32/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 1.6182 - accuracy: 0.2721 - val_loss: 1.6092 - val_accuracy: 0.2684\n",
            "Epoch 33/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 1.6182 - accuracy: 0.2575 - val_loss: 1.6092 - val_accuracy: 0.2684\n",
            "Epoch 34/500\n",
            "189/189 [==============================] - 63s 336ms/step - loss: 1.6136 - accuracy: 0.2693 - val_loss: 1.6092 - val_accuracy: 0.2684\n",
            "Epoch 35/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 1.6196 - accuracy: 0.2575 - val_loss: 1.6092 - val_accuracy: 0.2684\n",
            "Epoch 36/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 1.6162 - accuracy: 0.2634 - val_loss: 1.6092 - val_accuracy: 0.2684\n",
            "Epoch 37/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 1.6133 - accuracy: 0.2674 - val_loss: 1.6092 - val_accuracy: 0.2684\n",
            "Epoch 38/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 1.6100 - accuracy: 0.2689 - val_loss: 1.6091 - val_accuracy: 0.2684\n",
            "Epoch 39/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 1.6160 - accuracy: 0.2688 - val_loss: 1.6091 - val_accuracy: 0.2684\n",
            "Epoch 40/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 1.6130 - accuracy: 0.2658 - val_loss: 1.6091 - val_accuracy: 0.2684\n",
            "Epoch 41/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 1.6101 - accuracy: 0.2618 - val_loss: 1.6091 - val_accuracy: 0.2684\n",
            "Epoch 42/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 1.6089 - accuracy: 0.2681 - val_loss: 1.6091 - val_accuracy: 0.2684\n",
            "Epoch 43/500\n",
            "189/189 [==============================] - 65s 347ms/step - loss: 1.6144 - accuracy: 0.2623 - val_loss: 1.6091 - val_accuracy: 0.2684\n",
            "Epoch 44/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 1.6078 - accuracy: 0.2741 - val_loss: 1.6091 - val_accuracy: 0.2684\n",
            "Epoch 45/500\n",
            "189/189 [==============================] - 68s 362ms/step - loss: 1.6131 - accuracy: 0.2458 - val_loss: 1.6090 - val_accuracy: 0.2684\n",
            "Epoch 46/500\n",
            "189/189 [==============================] - 68s 360ms/step - loss: 1.6088 - accuracy: 0.2674 - val_loss: 1.6090 - val_accuracy: 0.2684\n",
            "Epoch 47/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 1.6097 - accuracy: 0.2721 - val_loss: 1.6090 - val_accuracy: 0.2684\n",
            "Epoch 48/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 1.6090 - accuracy: 0.2694 - val_loss: 1.6090 - val_accuracy: 0.2684\n",
            "Epoch 49/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 1.6130 - accuracy: 0.2537 - val_loss: 1.6090 - val_accuracy: 0.2684\n",
            "Epoch 50/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 1.6182 - accuracy: 0.2792 - val_loss: 1.6090 - val_accuracy: 0.2684\n",
            "Epoch 51/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 1.6093 - accuracy: 0.2588 - val_loss: 1.6090 - val_accuracy: 0.2684\n",
            "Epoch 52/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 1.6103 - accuracy: 0.2646 - val_loss: 1.6090 - val_accuracy: 0.2684\n",
            "Epoch 53/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 1.6077 - accuracy: 0.2756 - val_loss: 1.6089 - val_accuracy: 0.2684\n",
            "Epoch 54/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 1.6191 - accuracy: 0.2737 - val_loss: 1.6089 - val_accuracy: 0.2684\n",
            "Epoch 55/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 1.6099 - accuracy: 0.2764 - val_loss: 1.6089 - val_accuracy: 0.2684\n",
            "Epoch 56/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 1.6074 - accuracy: 0.2661 - val_loss: 1.6089 - val_accuracy: 0.2684\n",
            "Epoch 57/500\n",
            "189/189 [==============================] - 66s 351ms/step - loss: 1.6059 - accuracy: 0.2859 - val_loss: 1.6088 - val_accuracy: 0.2694\n",
            "Epoch 58/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 1.6043 - accuracy: 0.2628 - val_loss: 1.5958 - val_accuracy: 0.3357\n",
            "Epoch 59/500\n",
            "189/189 [==============================] - 66s 349ms/step - loss: 1.6144 - accuracy: 0.2517 - val_loss: 1.6089 - val_accuracy: 0.2684\n",
            "Epoch 60/500\n",
            "189/189 [==============================] - 63s 336ms/step - loss: 1.6067 - accuracy: 0.2683 - val_loss: 1.6088 - val_accuracy: 0.2684\n",
            "Epoch 61/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 1.6067 - accuracy: 0.3104 - val_loss: 1.5176 - val_accuracy: 0.3536\n",
            "Epoch 62/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 1.6269 - accuracy: 0.2259 - val_loss: 1.6088 - val_accuracy: 0.2694\n",
            "Epoch 63/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 1.6328 - accuracy: 0.2923 - val_loss: 1.6088 - val_accuracy: 0.2684\n",
            "Epoch 64/500\n",
            "189/189 [==============================] - 66s 349ms/step - loss: 1.5938 - accuracy: 0.2990 - val_loss: 1.5584 - val_accuracy: 0.3406\n",
            "Epoch 65/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 1.6017 - accuracy: 0.2815 - val_loss: 1.5853 - val_accuracy: 0.3506\n",
            "Epoch 66/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 1.5990 - accuracy: 0.2900 - val_loss: 1.5873 - val_accuracy: 0.3571\n",
            "Epoch 67/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 1.5815 - accuracy: 0.3118 - val_loss: 1.5347 - val_accuracy: 0.3536\n",
            "Epoch 68/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 1.5962 - accuracy: 0.3093 - val_loss: 1.5222 - val_accuracy: 0.3830\n",
            "Epoch 69/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 1.5849 - accuracy: 0.2933 - val_loss: 1.5299 - val_accuracy: 0.3601\n",
            "Epoch 70/500\n",
            "189/189 [==============================] - 68s 360ms/step - loss: 1.5637 - accuracy: 0.3398 - val_loss: 1.4905 - val_accuracy: 0.4019\n",
            "Epoch 71/500\n",
            "189/189 [==============================] - 69s 365ms/step - loss: 1.5692 - accuracy: 0.3224 - val_loss: 1.4795 - val_accuracy: 0.4019\n",
            "Epoch 72/500\n",
            "189/189 [==============================] - 67s 356ms/step - loss: 1.5688 - accuracy: 0.3181 - val_loss: 1.4889 - val_accuracy: 0.4358\n",
            "Epoch 73/500\n",
            "189/189 [==============================] - 68s 359ms/step - loss: 1.6292 - accuracy: 0.3602 - val_loss: 1.4759 - val_accuracy: 0.4377\n",
            "Epoch 74/500\n",
            "189/189 [==============================] - 67s 353ms/step - loss: 1.5409 - accuracy: 0.3572 - val_loss: 1.4496 - val_accuracy: 0.4462\n",
            "Epoch 75/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 1.5320 - accuracy: 0.3556 - val_loss: 1.4548 - val_accuracy: 0.4806\n",
            "Epoch 76/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 1.5169 - accuracy: 0.3841 - val_loss: 1.4345 - val_accuracy: 0.4841\n",
            "Epoch 77/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 1.5188 - accuracy: 0.3785 - val_loss: 1.4146 - val_accuracy: 0.4871\n",
            "Epoch 78/500\n",
            "189/189 [==============================] - 63s 331ms/step - loss: 1.5050 - accuracy: 0.3848 - val_loss: 1.4046 - val_accuracy: 0.4836\n",
            "Epoch 79/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 1.4797 - accuracy: 0.3949 - val_loss: 1.3903 - val_accuracy: 0.4875\n",
            "Epoch 80/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 1.4889 - accuracy: 0.3931 - val_loss: 1.3785 - val_accuracy: 0.5015\n",
            "Epoch 81/500\n",
            "189/189 [==============================] - 65s 347ms/step - loss: 1.4608 - accuracy: 0.4109 - val_loss: 1.3648 - val_accuracy: 0.5055\n",
            "Epoch 82/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 1.4575 - accuracy: 0.4213 - val_loss: 1.3496 - val_accuracy: 0.5149\n",
            "Epoch 83/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 1.4489 - accuracy: 0.4238 - val_loss: 1.3403 - val_accuracy: 0.5164\n",
            "Epoch 84/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 1.4313 - accuracy: 0.4366 - val_loss: 1.3316 - val_accuracy: 0.5080\n",
            "Epoch 85/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 1.3984 - accuracy: 0.4539 - val_loss: 1.3354 - val_accuracy: 0.4801\n",
            "Epoch 86/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 1.4083 - accuracy: 0.4497 - val_loss: 1.3266 - val_accuracy: 0.4776\n",
            "Epoch 87/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 1.4019 - accuracy: 0.4588 - val_loss: 1.3056 - val_accuracy: 0.4965\n",
            "Epoch 88/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 1.3772 - accuracy: 0.4583 - val_loss: 1.2892 - val_accuracy: 0.5125\n",
            "Epoch 89/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 1.3573 - accuracy: 0.4778 - val_loss: 1.2891 - val_accuracy: 0.4965\n",
            "Epoch 90/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 1.3597 - accuracy: 0.4763 - val_loss: 1.2699 - val_accuracy: 0.5189\n",
            "Epoch 91/500\n",
            "189/189 [==============================] - 63s 332ms/step - loss: 1.3417 - accuracy: 0.4761 - val_loss: 1.2633 - val_accuracy: 0.5189\n",
            "Epoch 92/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 1.3182 - accuracy: 0.4875 - val_loss: 1.2574 - val_accuracy: 0.5169\n",
            "Epoch 93/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 1.3261 - accuracy: 0.4955 - val_loss: 1.2438 - val_accuracy: 0.5304\n",
            "Epoch 94/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 1.2890 - accuracy: 0.5065 - val_loss: 1.2356 - val_accuracy: 0.5339\n",
            "Epoch 95/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 1.3060 - accuracy: 0.5070 - val_loss: 1.2252 - val_accuracy: 0.5359\n",
            "Epoch 96/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 1.4877 - accuracy: 0.5452 - val_loss: 1.2703 - val_accuracy: 0.4691\n",
            "Epoch 97/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 1.2730 - accuracy: 0.5136 - val_loss: 1.2017 - val_accuracy: 0.5458\n",
            "Epoch 98/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 1.2393 - accuracy: 0.5286 - val_loss: 1.1959 - val_accuracy: 0.5483\n",
            "Epoch 99/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 1.2326 - accuracy: 0.5359 - val_loss: 1.1961 - val_accuracy: 0.5488\n",
            "Epoch 100/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 1.2299 - accuracy: 0.5377 - val_loss: 1.1928 - val_accuracy: 0.5488\n",
            "Epoch 101/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 1.2043 - accuracy: 0.5422 - val_loss: 1.1743 - val_accuracy: 0.5563\n",
            "Epoch 102/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 1.1979 - accuracy: 0.5461 - val_loss: 1.1775 - val_accuracy: 0.5528\n",
            "Epoch 103/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 1.1908 - accuracy: 0.5518 - val_loss: 1.1672 - val_accuracy: 0.5533\n",
            "Epoch 104/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 1.1837 - accuracy: 0.5584 - val_loss: 1.1532 - val_accuracy: 0.5573\n",
            "Epoch 105/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 1.1619 - accuracy: 0.5634 - val_loss: 1.1440 - val_accuracy: 0.5603\n",
            "Epoch 106/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 1.1775 - accuracy: 0.5727 - val_loss: 1.1418 - val_accuracy: 0.5573\n",
            "Epoch 107/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 1.1523 - accuracy: 0.5608 - val_loss: 1.1227 - val_accuracy: 0.5627\n",
            "Epoch 108/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 1.1338 - accuracy: 0.5750 - val_loss: 1.1083 - val_accuracy: 0.5637\n",
            "Epoch 109/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 1.1236 - accuracy: 0.5759 - val_loss: 1.1049 - val_accuracy: 0.5647\n",
            "Epoch 110/500\n",
            "189/189 [==============================] - 66s 349ms/step - loss: 1.1089 - accuracy: 0.5852 - val_loss: 1.0919 - val_accuracy: 0.5697\n",
            "Epoch 111/500\n",
            "189/189 [==============================] - 67s 353ms/step - loss: 1.1111 - accuracy: 0.5785 - val_loss: 1.0799 - val_accuracy: 0.5722\n",
            "Epoch 112/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 1.0978 - accuracy: 0.5876 - val_loss: 1.0676 - val_accuracy: 0.5797\n",
            "Epoch 113/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 1.0915 - accuracy: 0.5898 - val_loss: 1.0567 - val_accuracy: 0.5901\n",
            "Epoch 114/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 1.0768 - accuracy: 0.5986 - val_loss: 1.0440 - val_accuracy: 0.5996\n",
            "Epoch 115/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 1.0692 - accuracy: 0.5961 - val_loss: 1.0334 - val_accuracy: 0.6081\n",
            "Epoch 116/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 1.0610 - accuracy: 0.6011 - val_loss: 1.0247 - val_accuracy: 0.6140\n",
            "Epoch 117/500\n",
            "189/189 [==============================] - 66s 349ms/step - loss: 1.0473 - accuracy: 0.6044 - val_loss: 1.0136 - val_accuracy: 0.6210\n",
            "Epoch 118/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 1.0362 - accuracy: 0.6084 - val_loss: 1.0026 - val_accuracy: 0.6265\n",
            "Epoch 119/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 1.0128 - accuracy: 0.6170 - val_loss: 2.1733 - val_accuracy: 0.4965\n",
            "Epoch 120/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 1.2044 - accuracy: 0.5840 - val_loss: 0.9742 - val_accuracy: 0.6424\n",
            "Epoch 121/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 1.0226 - accuracy: 0.6106 - val_loss: 0.9585 - val_accuracy: 0.6534\n",
            "Epoch 122/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 1.0070 - accuracy: 0.6255 - val_loss: 0.9629 - val_accuracy: 0.6494\n",
            "Epoch 123/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 1.0081 - accuracy: 0.6195 - val_loss: 0.9392 - val_accuracy: 0.6628\n",
            "Epoch 124/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.9941 - accuracy: 0.6277 - val_loss: 0.9372 - val_accuracy: 0.6673\n",
            "Epoch 125/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.9863 - accuracy: 0.6258 - val_loss: 0.9203 - val_accuracy: 0.6763\n",
            "Epoch 126/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.9723 - accuracy: 0.6318 - val_loss: 0.9118 - val_accuracy: 0.6838\n",
            "Epoch 127/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.9670 - accuracy: 0.6363 - val_loss: 0.9017 - val_accuracy: 0.6868\n",
            "Epoch 128/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.9691 - accuracy: 0.6321 - val_loss: 0.9033 - val_accuracy: 0.6887\n",
            "Epoch 129/500\n",
            "189/189 [==============================] - 63s 331ms/step - loss: 0.9581 - accuracy: 0.6361 - val_loss: 0.8959 - val_accuracy: 0.6892\n",
            "Epoch 130/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.9459 - accuracy: 0.6389 - val_loss: 0.8817 - val_accuracy: 0.6892\n",
            "Epoch 131/500\n",
            "189/189 [==============================] - 63s 331ms/step - loss: 0.9469 - accuracy: 0.6497 - val_loss: 0.8751 - val_accuracy: 0.6927\n",
            "Epoch 132/500\n",
            "189/189 [==============================] - 67s 357ms/step - loss: 0.9498 - accuracy: 0.6424 - val_loss: 0.8677 - val_accuracy: 0.6962\n",
            "Epoch 133/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.9364 - accuracy: 0.6438 - val_loss: 0.8604 - val_accuracy: 0.6982\n",
            "Epoch 134/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.9254 - accuracy: 0.6421 - val_loss: 0.8547 - val_accuracy: 0.7002\n",
            "Epoch 135/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.9129 - accuracy: 0.6516 - val_loss: 0.8527 - val_accuracy: 0.6977\n",
            "Epoch 136/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 0.9162 - accuracy: 0.6497 - val_loss: 0.8481 - val_accuracy: 0.6997\n",
            "Epoch 137/500\n",
            "189/189 [==============================] - 61s 325ms/step - loss: 0.9168 - accuracy: 0.6464 - val_loss: 0.8422 - val_accuracy: 0.7017\n",
            "Epoch 138/500\n",
            "189/189 [==============================] - 62s 330ms/step - loss: 0.9127 - accuracy: 0.6504 - val_loss: 0.8352 - val_accuracy: 0.7017\n",
            "Epoch 139/500\n",
            "189/189 [==============================] - 62s 329ms/step - loss: 0.9025 - accuracy: 0.6592 - val_loss: 0.8246 - val_accuracy: 0.7032\n",
            "Epoch 140/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.8878 - accuracy: 0.6605 - val_loss: 0.8265 - val_accuracy: 0.7007\n",
            "Epoch 141/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 0.8976 - accuracy: 0.6599 - val_loss: 0.8241 - val_accuracy: 0.7022\n",
            "Epoch 142/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.8856 - accuracy: 0.6622 - val_loss: 0.8219 - val_accuracy: 0.7027\n",
            "Epoch 143/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.8883 - accuracy: 0.6658 - val_loss: 0.8138 - val_accuracy: 0.7057\n",
            "Epoch 144/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.8719 - accuracy: 0.6624 - val_loss: 0.8097 - val_accuracy: 0.7057\n",
            "Epoch 145/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.8753 - accuracy: 0.6632 - val_loss: 0.8053 - val_accuracy: 0.7057\n",
            "Epoch 146/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.8767 - accuracy: 0.6650 - val_loss: 0.7984 - val_accuracy: 0.7067\n",
            "Epoch 147/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.8682 - accuracy: 0.6703 - val_loss: 0.7985 - val_accuracy: 0.7057\n",
            "Epoch 148/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 0.8616 - accuracy: 0.6736 - val_loss: 0.7947 - val_accuracy: 0.7062\n",
            "Epoch 149/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.8633 - accuracy: 0.6700 - val_loss: 0.7914 - val_accuracy: 0.7057\n",
            "Epoch 150/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 0.8669 - accuracy: 0.6781 - val_loss: 0.7892 - val_accuracy: 0.7047\n",
            "Epoch 151/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.8560 - accuracy: 0.6736 - val_loss: 0.7866 - val_accuracy: 0.7052\n",
            "Epoch 152/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 0.8504 - accuracy: 0.6766 - val_loss: 0.7801 - val_accuracy: 0.7072\n",
            "Epoch 153/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.8381 - accuracy: 0.6765 - val_loss: 0.7788 - val_accuracy: 0.7082\n",
            "Epoch 154/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.8529 - accuracy: 0.6765 - val_loss: 0.7788 - val_accuracy: 0.7077\n",
            "Epoch 155/500\n",
            "189/189 [==============================] - 62s 329ms/step - loss: 0.8320 - accuracy: 0.6826 - val_loss: 0.7787 - val_accuracy: 0.7082\n",
            "Epoch 156/500\n",
            "189/189 [==============================] - 63s 332ms/step - loss: 0.8349 - accuracy: 0.6781 - val_loss: 0.7684 - val_accuracy: 0.7082\n",
            "Epoch 157/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 0.8337 - accuracy: 0.6813 - val_loss: 0.7672 - val_accuracy: 0.7102\n",
            "Epoch 158/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.8195 - accuracy: 0.6864 - val_loss: 0.7659 - val_accuracy: 0.7087\n",
            "Epoch 159/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 0.8362 - accuracy: 0.6761 - val_loss: 0.7634 - val_accuracy: 0.7112\n",
            "Epoch 160/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.8231 - accuracy: 0.6806 - val_loss: 0.7640 - val_accuracy: 0.7097\n",
            "Epoch 161/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.8216 - accuracy: 0.6813 - val_loss: 0.7613 - val_accuracy: 0.7107\n",
            "Epoch 162/500\n",
            "189/189 [==============================] - 65s 347ms/step - loss: 0.8179 - accuracy: 0.6854 - val_loss: 0.7598 - val_accuracy: 0.7117\n",
            "Epoch 163/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.8201 - accuracy: 0.6809 - val_loss: 0.7576 - val_accuracy: 0.7102\n",
            "Epoch 164/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.8098 - accuracy: 0.6876 - val_loss: 0.7544 - val_accuracy: 0.7122\n",
            "Epoch 165/500\n",
            "189/189 [==============================] - 67s 354ms/step - loss: 0.8154 - accuracy: 0.6882 - val_loss: 0.7524 - val_accuracy: 0.7102\n",
            "Epoch 166/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.8030 - accuracy: 0.6919 - val_loss: 0.7465 - val_accuracy: 0.7092\n",
            "Epoch 167/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.8016 - accuracy: 0.6922 - val_loss: 0.7481 - val_accuracy: 0.7117\n",
            "Epoch 168/500\n",
            "189/189 [==============================] - 66s 349ms/step - loss: 0.7972 - accuracy: 0.6836 - val_loss: 0.7461 - val_accuracy: 0.7107\n",
            "Epoch 169/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.8020 - accuracy: 0.6944 - val_loss: 0.7448 - val_accuracy: 0.7136\n",
            "Epoch 170/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.7928 - accuracy: 0.6941 - val_loss: 0.7431 - val_accuracy: 0.7122\n",
            "Epoch 171/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.8003 - accuracy: 0.6947 - val_loss: 0.7420 - val_accuracy: 0.7141\n",
            "Epoch 172/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.7938 - accuracy: 0.6984 - val_loss: 0.7425 - val_accuracy: 0.7171\n",
            "Epoch 173/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.7875 - accuracy: 0.6946 - val_loss: 0.7391 - val_accuracy: 0.7151\n",
            "Epoch 174/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.7930 - accuracy: 0.6929 - val_loss: 0.7394 - val_accuracy: 0.7151\n",
            "Epoch 175/500\n",
            "189/189 [==============================] - 68s 359ms/step - loss: 0.7924 - accuracy: 0.6962 - val_loss: 0.7372 - val_accuracy: 0.7146\n",
            "Epoch 176/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.7846 - accuracy: 0.6990 - val_loss: 0.7369 - val_accuracy: 0.7151\n",
            "Epoch 177/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.7833 - accuracy: 0.7027 - val_loss: 0.7354 - val_accuracy: 0.7151\n",
            "Epoch 178/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.7865 - accuracy: 0.6916 - val_loss: 0.7355 - val_accuracy: 0.7156\n",
            "Epoch 179/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 0.7882 - accuracy: 0.6977 - val_loss: 0.7330 - val_accuracy: 0.7151\n",
            "Epoch 180/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 0.7845 - accuracy: 0.6979 - val_loss: 0.7329 - val_accuracy: 0.7151\n",
            "Epoch 181/500\n",
            "189/189 [==============================] - 63s 332ms/step - loss: 0.7790 - accuracy: 0.6970 - val_loss: 0.7302 - val_accuracy: 0.7191\n",
            "Epoch 182/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.7687 - accuracy: 0.7019 - val_loss: 0.7277 - val_accuracy: 0.7221\n",
            "Epoch 183/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.7782 - accuracy: 0.6962 - val_loss: 0.7288 - val_accuracy: 0.7201\n",
            "Epoch 184/500\n",
            "189/189 [==============================] - 62s 331ms/step - loss: 0.7725 - accuracy: 0.6952 - val_loss: 0.7267 - val_accuracy: 0.7201\n",
            "Epoch 185/500\n",
            "189/189 [==============================] - 62s 327ms/step - loss: 0.7714 - accuracy: 0.6969 - val_loss: 0.7271 - val_accuracy: 0.7196\n",
            "Epoch 186/500\n",
            "189/189 [==============================] - 62s 328ms/step - loss: 0.7631 - accuracy: 0.7032 - val_loss: 0.7245 - val_accuracy: 0.7216\n",
            "Epoch 187/500\n",
            "189/189 [==============================] - 62s 327ms/step - loss: 0.7604 - accuracy: 0.7075 - val_loss: 0.7241 - val_accuracy: 0.7206\n",
            "Epoch 188/500\n",
            "189/189 [==============================] - 62s 326ms/step - loss: 0.7632 - accuracy: 0.7027 - val_loss: 0.7212 - val_accuracy: 0.7211\n",
            "Epoch 189/500\n",
            "189/189 [==============================] - 61s 324ms/step - loss: 0.7618 - accuracy: 0.7072 - val_loss: 0.7211 - val_accuracy: 0.7231\n",
            "Epoch 190/500\n",
            "189/189 [==============================] - 61s 324ms/step - loss: 0.7625 - accuracy: 0.6972 - val_loss: 0.7216 - val_accuracy: 0.7246\n",
            "Epoch 191/500\n",
            "189/189 [==============================] - 62s 326ms/step - loss: 0.7537 - accuracy: 0.7053 - val_loss: 0.7204 - val_accuracy: 0.7206\n",
            "Epoch 192/500\n",
            "189/189 [==============================] - 61s 325ms/step - loss: 0.7608 - accuracy: 0.7029 - val_loss: 0.7193 - val_accuracy: 0.7211\n",
            "Epoch 193/500\n",
            "189/189 [==============================] - 62s 328ms/step - loss: 0.7545 - accuracy: 0.7047 - val_loss: 0.7175 - val_accuracy: 0.7216\n",
            "Epoch 194/500\n",
            "189/189 [==============================] - 62s 330ms/step - loss: 0.7508 - accuracy: 0.7120 - val_loss: 0.7183 - val_accuracy: 0.7216\n",
            "Epoch 195/500\n",
            "189/189 [==============================] - 63s 332ms/step - loss: 0.7546 - accuracy: 0.7063 - val_loss: 0.7156 - val_accuracy: 0.7241\n",
            "Epoch 196/500\n",
            "189/189 [==============================] - 62s 326ms/step - loss: 0.7465 - accuracy: 0.7077 - val_loss: 0.7140 - val_accuracy: 0.7251\n",
            "Epoch 197/500\n",
            "189/189 [==============================] - 62s 327ms/step - loss: 0.7527 - accuracy: 0.7042 - val_loss: 0.7153 - val_accuracy: 0.7221\n",
            "Epoch 198/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 0.7495 - accuracy: 0.7020 - val_loss: 0.7128 - val_accuracy: 0.7271\n",
            "Epoch 199/500\n",
            "189/189 [==============================] - 63s 332ms/step - loss: 0.7489 - accuracy: 0.7040 - val_loss: 0.7125 - val_accuracy: 0.7246\n",
            "Epoch 200/500\n",
            "189/189 [==============================] - 62s 330ms/step - loss: 0.7466 - accuracy: 0.7063 - val_loss: 0.7127 - val_accuracy: 0.7231\n",
            "Epoch 201/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.7429 - accuracy: 0.7090 - val_loss: 0.7109 - val_accuracy: 0.7256\n",
            "Epoch 202/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 0.7422 - accuracy: 0.7135 - val_loss: 0.7110 - val_accuracy: 0.7266\n",
            "Epoch 203/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 0.7418 - accuracy: 0.7110 - val_loss: 0.7106 - val_accuracy: 0.7256\n",
            "Epoch 204/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.7410 - accuracy: 0.7118 - val_loss: 0.7091 - val_accuracy: 0.7271\n",
            "Epoch 205/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.7366 - accuracy: 0.7103 - val_loss: 0.7093 - val_accuracy: 0.7276\n",
            "Epoch 206/500\n",
            "189/189 [==============================] - 63s 332ms/step - loss: 0.7377 - accuracy: 0.7120 - val_loss: 0.7058 - val_accuracy: 0.7296\n",
            "Epoch 207/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 0.7298 - accuracy: 0.7156 - val_loss: 0.7067 - val_accuracy: 0.7286\n",
            "Epoch 208/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 0.7348 - accuracy: 0.7131 - val_loss: 0.7069 - val_accuracy: 0.7296\n",
            "Epoch 209/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 0.7364 - accuracy: 0.7118 - val_loss: 0.7037 - val_accuracy: 0.7291\n",
            "Epoch 210/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.7381 - accuracy: 0.7120 - val_loss: 0.7045 - val_accuracy: 0.7291\n",
            "Epoch 211/500\n",
            "189/189 [==============================] - 67s 355ms/step - loss: 0.7337 - accuracy: 0.7123 - val_loss: 0.7044 - val_accuracy: 0.7281\n",
            "Epoch 212/500\n",
            "189/189 [==============================] - 66s 352ms/step - loss: 0.7333 - accuracy: 0.7151 - val_loss: 0.7041 - val_accuracy: 0.7281\n",
            "Epoch 213/500\n",
            "189/189 [==============================] - 65s 347ms/step - loss: 0.7251 - accuracy: 0.7176 - val_loss: 0.7017 - val_accuracy: 0.7296\n",
            "Epoch 214/500\n",
            "189/189 [==============================] - 67s 354ms/step - loss: 0.7296 - accuracy: 0.7126 - val_loss: 0.7011 - val_accuracy: 0.7301\n",
            "Epoch 215/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.7146 - accuracy: 0.7228 - val_loss: 0.7007 - val_accuracy: 0.7311\n",
            "Epoch 216/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.7249 - accuracy: 0.7175 - val_loss: 0.6999 - val_accuracy: 0.7331\n",
            "Epoch 217/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.7187 - accuracy: 0.7196 - val_loss: 0.6995 - val_accuracy: 0.7306\n",
            "Epoch 218/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.7174 - accuracy: 0.7228 - val_loss: 0.6995 - val_accuracy: 0.7356\n",
            "Epoch 219/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 0.7244 - accuracy: 0.7103 - val_loss: 0.6987 - val_accuracy: 0.7341\n",
            "Epoch 220/500\n",
            "189/189 [==============================] - 66s 351ms/step - loss: 0.7193 - accuracy: 0.7205 - val_loss: 0.6977 - val_accuracy: 0.7361\n",
            "Epoch 221/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.7250 - accuracy: 0.7173 - val_loss: 0.6983 - val_accuracy: 0.7346\n",
            "Epoch 222/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.7198 - accuracy: 0.7185 - val_loss: 0.6971 - val_accuracy: 0.7375\n",
            "Epoch 223/500\n",
            "189/189 [==============================] - 65s 341ms/step - loss: 0.7196 - accuracy: 0.7186 - val_loss: 0.6969 - val_accuracy: 0.7371\n",
            "Epoch 224/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.7150 - accuracy: 0.7234 - val_loss: 0.6945 - val_accuracy: 0.7375\n",
            "Epoch 225/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.7187 - accuracy: 0.7170 - val_loss: 0.6934 - val_accuracy: 0.7385\n",
            "Epoch 226/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.7086 - accuracy: 0.7205 - val_loss: 0.6948 - val_accuracy: 0.7361\n",
            "Epoch 227/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.7120 - accuracy: 0.7186 - val_loss: 0.6937 - val_accuracy: 0.7375\n",
            "Epoch 228/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 0.7120 - accuracy: 0.7214 - val_loss: 0.6944 - val_accuracy: 0.7375\n",
            "Epoch 229/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.7097 - accuracy: 0.7190 - val_loss: 0.6924 - val_accuracy: 0.7375\n",
            "Epoch 230/500\n",
            "189/189 [==============================] - 67s 355ms/step - loss: 0.7099 - accuracy: 0.7203 - val_loss: 0.6927 - val_accuracy: 0.7361\n",
            "Epoch 231/500\n",
            "189/189 [==============================] - 67s 356ms/step - loss: 0.7095 - accuracy: 0.7228 - val_loss: 0.6920 - val_accuracy: 0.7356\n",
            "Epoch 232/500\n",
            "189/189 [==============================] - 68s 359ms/step - loss: 0.7103 - accuracy: 0.7228 - val_loss: 0.6920 - val_accuracy: 0.7366\n",
            "Epoch 233/500\n",
            "189/189 [==============================] - 69s 365ms/step - loss: 0.7015 - accuracy: 0.7261 - val_loss: 0.6913 - val_accuracy: 0.7375\n",
            "Epoch 234/500\n",
            "189/189 [==============================] - 68s 358ms/step - loss: 0.7048 - accuracy: 0.7231 - val_loss: 0.6909 - val_accuracy: 0.7375\n",
            "Epoch 235/500\n",
            "189/189 [==============================] - 68s 358ms/step - loss: 0.7023 - accuracy: 0.7221 - val_loss: 0.6900 - val_accuracy: 0.7385\n",
            "Epoch 236/500\n",
            "189/189 [==============================] - 68s 361ms/step - loss: 0.7033 - accuracy: 0.7266 - val_loss: 0.6899 - val_accuracy: 0.7385\n",
            "Epoch 237/500\n",
            "189/189 [==============================] - 67s 355ms/step - loss: 0.7042 - accuracy: 0.7221 - val_loss: 0.6893 - val_accuracy: 0.7385\n",
            "Epoch 238/500\n",
            "189/189 [==============================] - 68s 357ms/step - loss: 0.7011 - accuracy: 0.7243 - val_loss: 0.6886 - val_accuracy: 0.7405\n",
            "Epoch 239/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.7014 - accuracy: 0.7259 - val_loss: 0.6869 - val_accuracy: 0.7425\n",
            "Epoch 240/500\n",
            "189/189 [==============================] - 66s 351ms/step - loss: 0.6983 - accuracy: 0.7324 - val_loss: 0.6870 - val_accuracy: 0.7420\n",
            "Epoch 241/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.7051 - accuracy: 0.7281 - val_loss: 0.6880 - val_accuracy: 0.7400\n",
            "Epoch 242/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.7012 - accuracy: 0.7268 - val_loss: 0.6872 - val_accuracy: 0.7410\n",
            "Epoch 243/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.6897 - accuracy: 0.7364 - val_loss: 0.6861 - val_accuracy: 0.7425\n",
            "Epoch 244/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.6965 - accuracy: 0.7288 - val_loss: 0.6854 - val_accuracy: 0.7430\n",
            "Epoch 245/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.6868 - accuracy: 0.7347 - val_loss: 0.6847 - val_accuracy: 0.7430\n",
            "Epoch 246/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.6928 - accuracy: 0.7239 - val_loss: 0.6845 - val_accuracy: 0.7425\n",
            "Epoch 247/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.6951 - accuracy: 0.7319 - val_loss: 0.6829 - val_accuracy: 0.7450\n",
            "Epoch 248/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.6815 - accuracy: 0.7304 - val_loss: 0.6837 - val_accuracy: 0.7440\n",
            "Epoch 249/500\n",
            "189/189 [==============================] - 63s 336ms/step - loss: 0.6924 - accuracy: 0.7304 - val_loss: 0.6826 - val_accuracy: 0.7440\n",
            "Epoch 250/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.6820 - accuracy: 0.7372 - val_loss: 0.6822 - val_accuracy: 0.7445\n",
            "Epoch 251/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.6913 - accuracy: 0.7302 - val_loss: 0.6829 - val_accuracy: 0.7425\n",
            "Epoch 252/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.6859 - accuracy: 0.7312 - val_loss: 0.6823 - val_accuracy: 0.7440\n",
            "Epoch 253/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.6869 - accuracy: 0.7326 - val_loss: 0.6800 - val_accuracy: 0.7440\n",
            "Epoch 254/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.6798 - accuracy: 0.7337 - val_loss: 0.6802 - val_accuracy: 0.7440\n",
            "Epoch 255/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.6824 - accuracy: 0.7364 - val_loss: 0.6809 - val_accuracy: 0.7445\n",
            "Epoch 256/500\n",
            "189/189 [==============================] - 69s 365ms/step - loss: 0.6820 - accuracy: 0.7369 - val_loss: 0.6806 - val_accuracy: 0.7445\n",
            "Epoch 257/500\n",
            "189/189 [==============================] - 67s 352ms/step - loss: 0.6788 - accuracy: 0.7367 - val_loss: 0.6807 - val_accuracy: 0.7445\n",
            "Epoch 258/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.6778 - accuracy: 0.7346 - val_loss: 0.6785 - val_accuracy: 0.7460\n",
            "Epoch 259/500\n",
            "189/189 [==============================] - 68s 361ms/step - loss: 0.6860 - accuracy: 0.7327 - val_loss: 0.6800 - val_accuracy: 0.7460\n",
            "Epoch 260/500\n",
            "189/189 [==============================] - 68s 362ms/step - loss: 0.6731 - accuracy: 0.7334 - val_loss: 0.6789 - val_accuracy: 0.7445\n",
            "Epoch 261/500\n",
            "189/189 [==============================] - 70s 368ms/step - loss: 0.6787 - accuracy: 0.7342 - val_loss: 0.6772 - val_accuracy: 0.7450\n",
            "Epoch 262/500\n",
            "189/189 [==============================] - 68s 358ms/step - loss: 0.6818 - accuracy: 0.7356 - val_loss: 0.6767 - val_accuracy: 0.7445\n",
            "Epoch 263/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.6728 - accuracy: 0.7377 - val_loss: 0.6758 - val_accuracy: 0.7440\n",
            "Epoch 264/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.6697 - accuracy: 0.7440 - val_loss: 0.6760 - val_accuracy: 0.7440\n",
            "Epoch 265/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.6725 - accuracy: 0.7395 - val_loss: 0.6760 - val_accuracy: 0.7435\n",
            "Epoch 266/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.6715 - accuracy: 0.7415 - val_loss: 0.6762 - val_accuracy: 0.7445\n",
            "Epoch 267/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.6746 - accuracy: 0.7375 - val_loss: 0.6744 - val_accuracy: 0.7460\n",
            "Epoch 268/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.6711 - accuracy: 0.7372 - val_loss: 0.6739 - val_accuracy: 0.7455\n",
            "Epoch 269/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 0.6733 - accuracy: 0.7425 - val_loss: 0.6735 - val_accuracy: 0.7445\n",
            "Epoch 270/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 0.6709 - accuracy: 0.7337 - val_loss: 0.6736 - val_accuracy: 0.7455\n",
            "Epoch 271/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.6705 - accuracy: 0.7379 - val_loss: 0.6737 - val_accuracy: 0.7445\n",
            "Epoch 272/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 0.6669 - accuracy: 0.7424 - val_loss: 0.6730 - val_accuracy: 0.7440\n",
            "Epoch 273/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.6678 - accuracy: 0.7419 - val_loss: 0.6722 - val_accuracy: 0.7440\n",
            "Epoch 274/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.6643 - accuracy: 0.7455 - val_loss: 0.6729 - val_accuracy: 0.7425\n",
            "Epoch 275/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.6611 - accuracy: 0.7425 - val_loss: 0.6728 - val_accuracy: 0.7445\n",
            "Epoch 276/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 0.6680 - accuracy: 0.7400 - val_loss: 0.6722 - val_accuracy: 0.7440\n",
            "Epoch 277/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.6620 - accuracy: 0.7435 - val_loss: 0.6706 - val_accuracy: 0.7465\n",
            "Epoch 278/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 0.6574 - accuracy: 0.7454 - val_loss: 0.6705 - val_accuracy: 0.7460\n",
            "Epoch 279/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.6625 - accuracy: 0.7435 - val_loss: 0.6713 - val_accuracy: 0.7440\n",
            "Epoch 280/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.6577 - accuracy: 0.7440 - val_loss: 0.6682 - val_accuracy: 0.7455\n",
            "Epoch 281/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 0.6656 - accuracy: 0.7379 - val_loss: 0.6680 - val_accuracy: 0.7460\n",
            "Epoch 282/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.6527 - accuracy: 0.7467 - val_loss: 0.6670 - val_accuracy: 0.7450\n",
            "Epoch 283/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.6558 - accuracy: 0.7447 - val_loss: 0.6682 - val_accuracy: 0.7450\n",
            "Epoch 284/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.6559 - accuracy: 0.7454 - val_loss: 0.6672 - val_accuracy: 0.7470\n",
            "Epoch 285/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.6552 - accuracy: 0.7452 - val_loss: 0.6665 - val_accuracy: 0.7460\n",
            "Epoch 286/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.6555 - accuracy: 0.7447 - val_loss: 0.6668 - val_accuracy: 0.7465\n",
            "Epoch 287/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.6571 - accuracy: 0.7477 - val_loss: 0.6665 - val_accuracy: 0.7470\n",
            "Epoch 288/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.6555 - accuracy: 0.7420 - val_loss: 0.6656 - val_accuracy: 0.7475\n",
            "Epoch 289/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 0.6473 - accuracy: 0.7460 - val_loss: 0.6642 - val_accuracy: 0.7475\n",
            "Epoch 290/500\n",
            "189/189 [==============================] - 63s 336ms/step - loss: 0.6480 - accuracy: 0.7508 - val_loss: 0.6627 - val_accuracy: 0.7500\n",
            "Epoch 291/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 0.6439 - accuracy: 0.7522 - val_loss: 0.6630 - val_accuracy: 0.7485\n",
            "Epoch 292/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.6473 - accuracy: 0.7507 - val_loss: 0.6633 - val_accuracy: 0.7470\n",
            "Epoch 293/500\n",
            "189/189 [==============================] - 68s 358ms/step - loss: 0.6510 - accuracy: 0.7447 - val_loss: 0.6626 - val_accuracy: 0.7495\n",
            "Epoch 294/500\n",
            "189/189 [==============================] - 67s 353ms/step - loss: 0.6436 - accuracy: 0.7498 - val_loss: 0.6630 - val_accuracy: 0.7475\n",
            "Epoch 295/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.6442 - accuracy: 0.7452 - val_loss: 0.6631 - val_accuracy: 0.7490\n",
            "Epoch 296/500\n",
            "189/189 [==============================] - 68s 358ms/step - loss: 0.6416 - accuracy: 0.7527 - val_loss: 0.6618 - val_accuracy: 0.7500\n",
            "Epoch 297/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.6470 - accuracy: 0.7488 - val_loss: 0.6609 - val_accuracy: 0.7505\n",
            "Epoch 298/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.6444 - accuracy: 0.7512 - val_loss: 0.6596 - val_accuracy: 0.7505\n",
            "Epoch 299/500\n",
            "189/189 [==============================] - 67s 352ms/step - loss: 0.6361 - accuracy: 0.7550 - val_loss: 0.6604 - val_accuracy: 0.7500\n",
            "Epoch 300/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 0.6409 - accuracy: 0.7510 - val_loss: 0.6595 - val_accuracy: 0.7495\n",
            "Epoch 301/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.6408 - accuracy: 0.7500 - val_loss: 0.6592 - val_accuracy: 0.7505\n",
            "Epoch 302/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 0.6318 - accuracy: 0.7581 - val_loss: 0.6589 - val_accuracy: 0.7505\n",
            "Epoch 303/500\n",
            "189/189 [==============================] - 64s 338ms/step - loss: 0.6408 - accuracy: 0.7545 - val_loss: 0.6584 - val_accuracy: 0.7525\n",
            "Epoch 304/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.6375 - accuracy: 0.7560 - val_loss: 0.6581 - val_accuracy: 0.7520\n",
            "Epoch 305/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.6329 - accuracy: 0.7525 - val_loss: 0.6575 - val_accuracy: 0.7505\n",
            "Epoch 306/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.6350 - accuracy: 0.7561 - val_loss: 0.6579 - val_accuracy: 0.7505\n",
            "Epoch 307/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.6352 - accuracy: 0.7537 - val_loss: 0.6576 - val_accuracy: 0.7510\n",
            "Epoch 308/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.6303 - accuracy: 0.7561 - val_loss: 0.6552 - val_accuracy: 0.7535\n",
            "Epoch 309/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.6288 - accuracy: 0.7595 - val_loss: 0.6561 - val_accuracy: 0.7535\n",
            "Epoch 310/500\n",
            "189/189 [==============================] - 67s 354ms/step - loss: 0.6325 - accuracy: 0.7566 - val_loss: 0.6555 - val_accuracy: 0.7550\n",
            "Epoch 311/500\n",
            "189/189 [==============================] - 68s 361ms/step - loss: 0.6246 - accuracy: 0.7576 - val_loss: 0.6553 - val_accuracy: 0.7540\n",
            "Epoch 312/500\n",
            "189/189 [==============================] - 66s 352ms/step - loss: 0.6290 - accuracy: 0.7565 - val_loss: 0.6575 - val_accuracy: 0.7530\n",
            "Epoch 313/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.6285 - accuracy: 0.7563 - val_loss: 0.6557 - val_accuracy: 0.7550\n",
            "Epoch 314/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.6236 - accuracy: 0.7616 - val_loss: 0.6543 - val_accuracy: 0.7550\n",
            "Epoch 315/500\n",
            "189/189 [==============================] - 67s 356ms/step - loss: 0.6293 - accuracy: 0.7583 - val_loss: 0.6543 - val_accuracy: 0.7555\n",
            "Epoch 316/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.6228 - accuracy: 0.7636 - val_loss: 0.6535 - val_accuracy: 0.7555\n",
            "Epoch 317/500\n",
            "189/189 [==============================] - 67s 352ms/step - loss: 0.6285 - accuracy: 0.7568 - val_loss: 0.6542 - val_accuracy: 0.7550\n",
            "Epoch 318/500\n",
            "189/189 [==============================] - 67s 353ms/step - loss: 0.6218 - accuracy: 0.7573 - val_loss: 0.6537 - val_accuracy: 0.7550\n",
            "Epoch 319/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.6141 - accuracy: 0.7591 - val_loss: 0.6525 - val_accuracy: 0.7585\n",
            "Epoch 320/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.6210 - accuracy: 0.7628 - val_loss: 0.6520 - val_accuracy: 0.7585\n",
            "Epoch 321/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.6074 - accuracy: 0.7669 - val_loss: 0.6522 - val_accuracy: 0.7540\n",
            "Epoch 322/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 0.6124 - accuracy: 0.7686 - val_loss: 0.6528 - val_accuracy: 0.7555\n",
            "Epoch 323/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.6138 - accuracy: 0.7658 - val_loss: 0.6531 - val_accuracy: 0.7550\n",
            "Epoch 324/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 0.6168 - accuracy: 0.7608 - val_loss: 0.6519 - val_accuracy: 0.7555\n",
            "Epoch 325/500\n",
            "189/189 [==============================] - 62s 330ms/step - loss: 0.6122 - accuracy: 0.7606 - val_loss: 0.6523 - val_accuracy: 0.7570\n",
            "Epoch 326/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 0.6127 - accuracy: 0.7608 - val_loss: 0.6504 - val_accuracy: 0.7560\n",
            "Epoch 327/500\n",
            "189/189 [==============================] - 62s 330ms/step - loss: 0.6074 - accuracy: 0.7659 - val_loss: 0.6505 - val_accuracy: 0.7560\n",
            "Epoch 328/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.6048 - accuracy: 0.7669 - val_loss: 0.6508 - val_accuracy: 0.7560\n",
            "Epoch 329/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.6088 - accuracy: 0.7643 - val_loss: 0.6506 - val_accuracy: 0.7565\n",
            "Epoch 330/500\n",
            "189/189 [==============================] - 63s 336ms/step - loss: 0.6091 - accuracy: 0.7629 - val_loss: 0.6520 - val_accuracy: 0.7555\n",
            "Epoch 331/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.6056 - accuracy: 0.7631 - val_loss: 0.6506 - val_accuracy: 0.7550\n",
            "Epoch 332/500\n",
            "189/189 [==============================] - 65s 341ms/step - loss: 0.6024 - accuracy: 0.7696 - val_loss: 0.6489 - val_accuracy: 0.7555\n",
            "Epoch 333/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 0.5978 - accuracy: 0.7649 - val_loss: 0.6501 - val_accuracy: 0.7565\n",
            "Epoch 334/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 0.5956 - accuracy: 0.7726 - val_loss: 0.6511 - val_accuracy: 0.7550\n",
            "Epoch 335/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.6086 - accuracy: 0.7704 - val_loss: 0.6503 - val_accuracy: 0.7555\n",
            "Epoch 336/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 0.5946 - accuracy: 0.7741 - val_loss: 0.6506 - val_accuracy: 0.7555\n",
            "Epoch 337/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.5970 - accuracy: 0.7691 - val_loss: 0.6510 - val_accuracy: 0.7565\n",
            "Epoch 338/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 0.5960 - accuracy: 0.7741 - val_loss: 0.6496 - val_accuracy: 0.7565\n",
            "Epoch 339/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.5999 - accuracy: 0.7709 - val_loss: 0.6474 - val_accuracy: 0.7580\n",
            "Epoch 340/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 0.5941 - accuracy: 0.7734 - val_loss: 0.6468 - val_accuracy: 0.7580\n",
            "Epoch 341/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.5928 - accuracy: 0.7772 - val_loss: 0.6455 - val_accuracy: 0.7585\n",
            "Epoch 342/500\n",
            "189/189 [==============================] - 66s 349ms/step - loss: 0.5898 - accuracy: 0.7751 - val_loss: 0.6438 - val_accuracy: 0.7590\n",
            "Epoch 343/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.5919 - accuracy: 0.7747 - val_loss: 0.6465 - val_accuracy: 0.7590\n",
            "Epoch 344/500\n",
            "189/189 [==============================] - 66s 349ms/step - loss: 0.5879 - accuracy: 0.7769 - val_loss: 0.6471 - val_accuracy: 0.7600\n",
            "Epoch 345/500\n",
            "189/189 [==============================] - 66s 352ms/step - loss: 0.5932 - accuracy: 0.7736 - val_loss: 0.6479 - val_accuracy: 0.7585\n",
            "Epoch 346/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.5926 - accuracy: 0.7802 - val_loss: 0.6443 - val_accuracy: 0.7590\n",
            "Epoch 347/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.5883 - accuracy: 0.7784 - val_loss: 0.6455 - val_accuracy: 0.7585\n",
            "Epoch 348/500\n",
            "189/189 [==============================] - 63s 336ms/step - loss: 0.5868 - accuracy: 0.7767 - val_loss: 0.6459 - val_accuracy: 0.7555\n",
            "Epoch 349/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.5827 - accuracy: 0.7766 - val_loss: 0.6434 - val_accuracy: 0.7615\n",
            "Epoch 350/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.5821 - accuracy: 0.7749 - val_loss: 0.6435 - val_accuracy: 0.7620\n",
            "Epoch 351/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.5817 - accuracy: 0.7779 - val_loss: 0.6431 - val_accuracy: 0.7595\n",
            "Epoch 352/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 0.5777 - accuracy: 0.7829 - val_loss: 0.6448 - val_accuracy: 0.7580\n",
            "Epoch 353/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 0.5861 - accuracy: 0.7761 - val_loss: 0.6428 - val_accuracy: 0.7629\n",
            "Epoch 354/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 0.5816 - accuracy: 0.7824 - val_loss: 0.6432 - val_accuracy: 0.7610\n",
            "Epoch 355/500\n",
            "189/189 [==============================] - 65s 341ms/step - loss: 0.5804 - accuracy: 0.7805 - val_loss: 0.6430 - val_accuracy: 0.7605\n",
            "Epoch 356/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.5793 - accuracy: 0.7815 - val_loss: 0.6414 - val_accuracy: 0.7615\n",
            "Epoch 357/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.5797 - accuracy: 0.7787 - val_loss: 0.6420 - val_accuracy: 0.7590\n",
            "Epoch 358/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 0.5809 - accuracy: 0.7772 - val_loss: 0.6418 - val_accuracy: 0.7585\n",
            "Epoch 359/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.5828 - accuracy: 0.7777 - val_loss: 0.6429 - val_accuracy: 0.7590\n",
            "Epoch 360/500\n",
            "189/189 [==============================] - 68s 360ms/step - loss: 0.5707 - accuracy: 0.7864 - val_loss: 0.6407 - val_accuracy: 0.7600\n",
            "Epoch 361/500\n",
            "189/189 [==============================] - 67s 355ms/step - loss: 0.5723 - accuracy: 0.7805 - val_loss: 0.6427 - val_accuracy: 0.7600\n",
            "Epoch 362/500\n",
            "189/189 [==============================] - 67s 355ms/step - loss: 0.5747 - accuracy: 0.7789 - val_loss: 0.6408 - val_accuracy: 0.7610\n",
            "Epoch 363/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.5640 - accuracy: 0.7898 - val_loss: 0.6426 - val_accuracy: 0.7590\n",
            "Epoch 364/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.5685 - accuracy: 0.7830 - val_loss: 0.6418 - val_accuracy: 0.7595\n",
            "Epoch 365/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.5633 - accuracy: 0.7869 - val_loss: 0.6415 - val_accuracy: 0.7595\n",
            "Epoch 366/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.5575 - accuracy: 0.7898 - val_loss: 0.6384 - val_accuracy: 0.7590\n",
            "Epoch 367/500\n",
            "189/189 [==============================] - 66s 351ms/step - loss: 0.5600 - accuracy: 0.7857 - val_loss: 0.6369 - val_accuracy: 0.7605\n",
            "Epoch 368/500\n",
            "189/189 [==============================] - 67s 356ms/step - loss: 0.5611 - accuracy: 0.7892 - val_loss: 0.6372 - val_accuracy: 0.7610\n",
            "Epoch 369/500\n",
            "189/189 [==============================] - 69s 364ms/step - loss: 0.5665 - accuracy: 0.7814 - val_loss: 0.6371 - val_accuracy: 0.7590\n",
            "Epoch 370/500\n",
            "189/189 [==============================] - 66s 352ms/step - loss: 0.5577 - accuracy: 0.7862 - val_loss: 0.6386 - val_accuracy: 0.7615\n",
            "Epoch 371/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.5616 - accuracy: 0.7852 - val_loss: 0.6365 - val_accuracy: 0.7610\n",
            "Epoch 372/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 0.5572 - accuracy: 0.7888 - val_loss: 0.6359 - val_accuracy: 0.7600\n",
            "Epoch 373/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.5527 - accuracy: 0.7918 - val_loss: 0.6360 - val_accuracy: 0.7605\n",
            "Epoch 374/500\n",
            "189/189 [==============================] - 68s 361ms/step - loss: 0.5545 - accuracy: 0.7888 - val_loss: 0.6368 - val_accuracy: 0.7610\n",
            "Epoch 375/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.5514 - accuracy: 0.7877 - val_loss: 0.6353 - val_accuracy: 0.7620\n",
            "Epoch 376/500\n",
            "189/189 [==============================] - 66s 349ms/step - loss: 0.5488 - accuracy: 0.7933 - val_loss: 0.6351 - val_accuracy: 0.7634\n",
            "Epoch 377/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 0.5493 - accuracy: 0.7908 - val_loss: 0.6370 - val_accuracy: 0.7639\n",
            "Epoch 378/500\n",
            "189/189 [==============================] - 67s 353ms/step - loss: 0.5475 - accuracy: 0.7928 - val_loss: 0.6342 - val_accuracy: 0.7620\n",
            "Epoch 379/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.5475 - accuracy: 0.7928 - val_loss: 0.6341 - val_accuracy: 0.7625\n",
            "Epoch 380/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.5533 - accuracy: 0.7888 - val_loss: 0.6345 - val_accuracy: 0.7615\n",
            "Epoch 381/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 0.5490 - accuracy: 0.7917 - val_loss: 0.6363 - val_accuracy: 0.7620\n",
            "Epoch 382/500\n",
            "189/189 [==============================] - 68s 358ms/step - loss: 0.5430 - accuracy: 0.7945 - val_loss: 0.6342 - val_accuracy: 0.7629\n",
            "Epoch 383/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.5436 - accuracy: 0.7925 - val_loss: 0.6317 - val_accuracy: 0.7620\n",
            "Epoch 384/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.5356 - accuracy: 0.8010 - val_loss: 0.6332 - val_accuracy: 0.7625\n",
            "Epoch 385/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.5403 - accuracy: 0.8003 - val_loss: 0.6322 - val_accuracy: 0.7639\n",
            "Epoch 386/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 0.5337 - accuracy: 0.7953 - val_loss: 0.6325 - val_accuracy: 0.7659\n",
            "Epoch 387/500\n",
            "189/189 [==============================] - 63s 335ms/step - loss: 0.5408 - accuracy: 0.7935 - val_loss: 0.6337 - val_accuracy: 0.7629\n",
            "Epoch 388/500\n",
            "189/189 [==============================] - 63s 336ms/step - loss: 0.5333 - accuracy: 0.8006 - val_loss: 0.6318 - val_accuracy: 0.7639\n",
            "Epoch 389/500\n",
            "189/189 [==============================] - 64s 336ms/step - loss: 0.5307 - accuracy: 0.8008 - val_loss: 0.6319 - val_accuracy: 0.7644\n",
            "Epoch 390/500\n",
            "189/189 [==============================] - 63s 331ms/step - loss: 0.5343 - accuracy: 0.8016 - val_loss: 0.6315 - val_accuracy: 0.7649\n",
            "Epoch 391/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.5303 - accuracy: 0.8011 - val_loss: 0.6288 - val_accuracy: 0.7644\n",
            "Epoch 392/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.5310 - accuracy: 0.8025 - val_loss: 0.6330 - val_accuracy: 0.7674\n",
            "Epoch 393/500\n",
            "189/189 [==============================] - 63s 333ms/step - loss: 0.5283 - accuracy: 0.7988 - val_loss: 0.6302 - val_accuracy: 0.7684\n",
            "Epoch 394/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.5279 - accuracy: 0.8023 - val_loss: 0.6289 - val_accuracy: 0.7669\n",
            "Epoch 395/500\n",
            "189/189 [==============================] - 65s 341ms/step - loss: 0.5215 - accuracy: 0.8109 - val_loss: 0.6297 - val_accuracy: 0.7659\n",
            "Epoch 396/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.5285 - accuracy: 0.8031 - val_loss: 0.6315 - val_accuracy: 0.7659\n",
            "Epoch 397/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.5323 - accuracy: 0.8001 - val_loss: 0.6291 - val_accuracy: 0.7674\n",
            "Epoch 398/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 0.5242 - accuracy: 0.8061 - val_loss: 0.6296 - val_accuracy: 0.7674\n",
            "Epoch 399/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.5187 - accuracy: 0.8038 - val_loss: 0.6277 - val_accuracy: 0.7664\n",
            "Epoch 400/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 0.5248 - accuracy: 0.8049 - val_loss: 0.6264 - val_accuracy: 0.7709\n",
            "Epoch 401/500\n",
            "189/189 [==============================] - 64s 337ms/step - loss: 0.5120 - accuracy: 0.8103 - val_loss: 0.6241 - val_accuracy: 0.7684\n",
            "Epoch 402/500\n",
            "189/189 [==============================] - 62s 328ms/step - loss: 0.5154 - accuracy: 0.8025 - val_loss: 0.6243 - val_accuracy: 0.7679\n",
            "Epoch 403/500\n",
            "189/189 [==============================] - 63s 334ms/step - loss: 0.5174 - accuracy: 0.8081 - val_loss: 0.6237 - val_accuracy: 0.7669\n",
            "Epoch 404/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.5158 - accuracy: 0.8142 - val_loss: 0.6241 - val_accuracy: 0.7699\n",
            "Epoch 405/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.5128 - accuracy: 0.8099 - val_loss: 0.6228 - val_accuracy: 0.7689\n",
            "Epoch 406/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.5110 - accuracy: 0.8081 - val_loss: 0.6228 - val_accuracy: 0.7694\n",
            "Epoch 407/500\n",
            "189/189 [==============================] - 64s 339ms/step - loss: 0.5059 - accuracy: 0.8126 - val_loss: 0.6240 - val_accuracy: 0.7719\n",
            "Epoch 408/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.5014 - accuracy: 0.8134 - val_loss: 0.6279 - val_accuracy: 0.7719\n",
            "Epoch 409/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.5083 - accuracy: 0.8124 - val_loss: 0.6272 - val_accuracy: 0.7704\n",
            "Epoch 410/500\n",
            "189/189 [==============================] - 67s 354ms/step - loss: 0.5069 - accuracy: 0.8136 - val_loss: 0.6284 - val_accuracy: 0.7704\n",
            "Epoch 411/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.5090 - accuracy: 0.8091 - val_loss: 0.6249 - val_accuracy: 0.7729\n",
            "Epoch 412/500\n",
            "189/189 [==============================] - 68s 359ms/step - loss: 0.5005 - accuracy: 0.8134 - val_loss: 0.6230 - val_accuracy: 0.7714\n",
            "Epoch 413/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.5105 - accuracy: 0.8088 - val_loss: 0.6242 - val_accuracy: 0.7719\n",
            "Epoch 414/500\n",
            "189/189 [==============================] - 65s 343ms/step - loss: 0.4954 - accuracy: 0.8152 - val_loss: 0.6211 - val_accuracy: 0.7724\n",
            "Epoch 415/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.4995 - accuracy: 0.8142 - val_loss: 0.6235 - val_accuracy: 0.7714\n",
            "Epoch 416/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.4980 - accuracy: 0.8166 - val_loss: 0.6198 - val_accuracy: 0.7734\n",
            "Epoch 417/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.4944 - accuracy: 0.8186 - val_loss: 0.6213 - val_accuracy: 0.7734\n",
            "Epoch 418/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.4969 - accuracy: 0.8176 - val_loss: 0.6202 - val_accuracy: 0.7764\n",
            "Epoch 419/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.4917 - accuracy: 0.8194 - val_loss: 0.6200 - val_accuracy: 0.7744\n",
            "Epoch 420/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.4856 - accuracy: 0.8177 - val_loss: 0.6171 - val_accuracy: 0.7764\n",
            "Epoch 421/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.4907 - accuracy: 0.8177 - val_loss: 0.6162 - val_accuracy: 0.7779\n",
            "Epoch 422/500\n",
            "189/189 [==============================] - 64s 340ms/step - loss: 0.4884 - accuracy: 0.8222 - val_loss: 0.6149 - val_accuracy: 0.7794\n",
            "Epoch 423/500\n",
            "189/189 [==============================] - 65s 342ms/step - loss: 0.4906 - accuracy: 0.8177 - val_loss: 0.6143 - val_accuracy: 0.7784\n",
            "Epoch 424/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.4851 - accuracy: 0.8191 - val_loss: 0.6172 - val_accuracy: 0.7789\n",
            "Epoch 425/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.4886 - accuracy: 0.8202 - val_loss: 0.6165 - val_accuracy: 0.7779\n",
            "Epoch 426/500\n",
            "189/189 [==============================] - 68s 361ms/step - loss: 0.4770 - accuracy: 0.8234 - val_loss: 0.6199 - val_accuracy: 0.7789\n",
            "Epoch 427/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.4856 - accuracy: 0.8179 - val_loss: 0.6165 - val_accuracy: 0.7769\n",
            "Epoch 428/500\n",
            "189/189 [==============================] - 66s 351ms/step - loss: 0.4773 - accuracy: 0.8277 - val_loss: 0.6159 - val_accuracy: 0.7799\n",
            "Epoch 429/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.4771 - accuracy: 0.8219 - val_loss: 0.6181 - val_accuracy: 0.7764\n",
            "Epoch 430/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.4809 - accuracy: 0.8224 - val_loss: 0.6172 - val_accuracy: 0.7784\n",
            "Epoch 431/500\n",
            "189/189 [==============================] - 67s 355ms/step - loss: 0.4748 - accuracy: 0.8290 - val_loss: 0.6151 - val_accuracy: 0.7804\n",
            "Epoch 432/500\n",
            "189/189 [==============================] - 67s 355ms/step - loss: 0.4745 - accuracy: 0.8207 - val_loss: 0.6162 - val_accuracy: 0.7789\n",
            "Epoch 433/500\n",
            "189/189 [==============================] - 68s 358ms/step - loss: 0.4785 - accuracy: 0.8224 - val_loss: 0.6124 - val_accuracy: 0.7799\n",
            "Epoch 434/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.4764 - accuracy: 0.8247 - val_loss: 0.6195 - val_accuracy: 0.7784\n",
            "Epoch 435/500\n",
            "189/189 [==============================] - 67s 352ms/step - loss: 0.4732 - accuracy: 0.8242 - val_loss: 0.6128 - val_accuracy: 0.7779\n",
            "Epoch 436/500\n",
            "189/189 [==============================] - 68s 359ms/step - loss: 0.4674 - accuracy: 0.8342 - val_loss: 0.6159 - val_accuracy: 0.7769\n",
            "Epoch 437/500\n",
            "189/189 [==============================] - 68s 362ms/step - loss: 0.4735 - accuracy: 0.8293 - val_loss: 0.6120 - val_accuracy: 0.7789\n",
            "Epoch 438/500\n",
            "189/189 [==============================] - 67s 356ms/step - loss: 0.4758 - accuracy: 0.8252 - val_loss: 0.6100 - val_accuracy: 0.7804\n",
            "Epoch 439/500\n",
            "189/189 [==============================] - 68s 359ms/step - loss: 0.4656 - accuracy: 0.8269 - val_loss: 0.6115 - val_accuracy: 0.7794\n",
            "Epoch 440/500\n",
            "189/189 [==============================] - 67s 356ms/step - loss: 0.4602 - accuracy: 0.8307 - val_loss: 0.6113 - val_accuracy: 0.7824\n",
            "Epoch 441/500\n",
            "189/189 [==============================] - 68s 358ms/step - loss: 0.4655 - accuracy: 0.8280 - val_loss: 0.6104 - val_accuracy: 0.7814\n",
            "Epoch 442/500\n",
            "189/189 [==============================] - 68s 358ms/step - loss: 0.4610 - accuracy: 0.8272 - val_loss: 0.6130 - val_accuracy: 0.7794\n",
            "Epoch 443/500\n",
            "189/189 [==============================] - 68s 357ms/step - loss: 0.4616 - accuracy: 0.8322 - val_loss: 0.6114 - val_accuracy: 0.7809\n",
            "Epoch 444/500\n",
            "189/189 [==============================] - 67s 356ms/step - loss: 0.4562 - accuracy: 0.8340 - val_loss: 0.6105 - val_accuracy: 0.7819\n",
            "Epoch 445/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.4613 - accuracy: 0.8295 - val_loss: 0.6097 - val_accuracy: 0.7829\n",
            "Epoch 446/500\n",
            "189/189 [==============================] - 67s 353ms/step - loss: 0.4533 - accuracy: 0.8353 - val_loss: 0.6078 - val_accuracy: 0.7839\n",
            "Epoch 447/500\n",
            "189/189 [==============================] - 66s 351ms/step - loss: 0.4499 - accuracy: 0.8391 - val_loss: 0.6107 - val_accuracy: 0.7829\n",
            "Epoch 448/500\n",
            "189/189 [==============================] - 67s 353ms/step - loss: 0.4549 - accuracy: 0.8327 - val_loss: 0.6092 - val_accuracy: 0.7824\n",
            "Epoch 449/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.4502 - accuracy: 0.8343 - val_loss: 0.6071 - val_accuracy: 0.7819\n",
            "Epoch 450/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.4540 - accuracy: 0.8337 - val_loss: 0.6084 - val_accuracy: 0.7794\n",
            "Epoch 451/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.4512 - accuracy: 0.8342 - val_loss: 0.6053 - val_accuracy: 0.7814\n",
            "Epoch 452/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.4495 - accuracy: 0.8352 - val_loss: 0.6071 - val_accuracy: 0.7814\n",
            "Epoch 453/500\n",
            "189/189 [==============================] - 68s 360ms/step - loss: 0.4420 - accuracy: 0.8426 - val_loss: 0.6082 - val_accuracy: 0.7804\n",
            "Epoch 454/500\n",
            "189/189 [==============================] - 67s 354ms/step - loss: 0.4428 - accuracy: 0.8352 - val_loss: 0.6033 - val_accuracy: 0.7819\n",
            "Epoch 455/500\n",
            "189/189 [==============================] - 78s 414ms/step - loss: 0.4359 - accuracy: 0.8423 - val_loss: 0.6070 - val_accuracy: 0.7794\n",
            "Epoch 456/500\n",
            "189/189 [==============================] - 76s 399ms/step - loss: 0.4419 - accuracy: 0.8367 - val_loss: 0.6053 - val_accuracy: 0.7794\n",
            "Epoch 457/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.4396 - accuracy: 0.8408 - val_loss: 0.6042 - val_accuracy: 0.7804\n",
            "Epoch 458/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.4398 - accuracy: 0.8400 - val_loss: 0.6062 - val_accuracy: 0.7799\n",
            "Epoch 459/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.4399 - accuracy: 0.8388 - val_loss: 0.6081 - val_accuracy: 0.7784\n",
            "Epoch 460/500\n",
            "189/189 [==============================] - 65s 345ms/step - loss: 0.4265 - accuracy: 0.8405 - val_loss: 0.6090 - val_accuracy: 0.7814\n",
            "Epoch 461/500\n",
            "189/189 [==============================] - 67s 354ms/step - loss: 0.4287 - accuracy: 0.8440 - val_loss: 0.6070 - val_accuracy: 0.7824\n",
            "Epoch 462/500\n",
            "189/189 [==============================] - 65s 344ms/step - loss: 0.4293 - accuracy: 0.8416 - val_loss: 0.6066 - val_accuracy: 0.7799\n",
            "Epoch 463/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.4306 - accuracy: 0.8435 - val_loss: 0.6043 - val_accuracy: 0.7804\n",
            "Epoch 464/500\n",
            "189/189 [==============================] - 67s 354ms/step - loss: 0.4253 - accuracy: 0.8463 - val_loss: 0.6044 - val_accuracy: 0.7804\n",
            "Epoch 465/500\n",
            "189/189 [==============================] - 67s 352ms/step - loss: 0.4252 - accuracy: 0.8423 - val_loss: 0.6047 - val_accuracy: 0.7784\n",
            "Epoch 466/500\n",
            "189/189 [==============================] - 67s 356ms/step - loss: 0.4245 - accuracy: 0.8459 - val_loss: 0.6038 - val_accuracy: 0.7779\n",
            "Epoch 467/500\n",
            "189/189 [==============================] - 68s 360ms/step - loss: 0.4263 - accuracy: 0.8459 - val_loss: 0.6068 - val_accuracy: 0.7794\n",
            "Epoch 468/500\n",
            "189/189 [==============================] - 68s 360ms/step - loss: 0.4172 - accuracy: 0.8461 - val_loss: 0.6077 - val_accuracy: 0.7819\n",
            "Epoch 469/500\n",
            "189/189 [==============================] - 67s 356ms/step - loss: 0.4213 - accuracy: 0.8466 - val_loss: 0.6050 - val_accuracy: 0.7829\n",
            "Epoch 470/500\n",
            "189/189 [==============================] - 68s 358ms/step - loss: 0.4209 - accuracy: 0.8463 - val_loss: 0.6058 - val_accuracy: 0.7829\n",
            "Epoch 471/500\n",
            "189/189 [==============================] - 67s 354ms/step - loss: 0.4154 - accuracy: 0.8498 - val_loss: 0.6090 - val_accuracy: 0.7809\n",
            "Epoch 472/500\n",
            "189/189 [==============================] - 67s 352ms/step - loss: 0.4174 - accuracy: 0.8436 - val_loss: 0.6058 - val_accuracy: 0.7799\n",
            "Epoch 473/500\n",
            "189/189 [==============================] - 67s 354ms/step - loss: 0.4159 - accuracy: 0.8526 - val_loss: 0.6046 - val_accuracy: 0.7799\n",
            "Epoch 474/500\n",
            "189/189 [==============================] - 68s 362ms/step - loss: 0.4094 - accuracy: 0.8513 - val_loss: 0.6090 - val_accuracy: 0.7809\n",
            "Epoch 475/500\n",
            "189/189 [==============================] - 67s 355ms/step - loss: 0.4119 - accuracy: 0.8479 - val_loss: 0.6074 - val_accuracy: 0.7789\n",
            "Epoch 476/500\n",
            "189/189 [==============================] - 67s 353ms/step - loss: 0.4155 - accuracy: 0.8479 - val_loss: 0.6047 - val_accuracy: 0.7814\n",
            "Epoch 477/500\n",
            "189/189 [==============================] - 67s 352ms/step - loss: 0.4140 - accuracy: 0.8453 - val_loss: 0.6011 - val_accuracy: 0.7844\n",
            "Epoch 478/500\n",
            "189/189 [==============================] - 70s 372ms/step - loss: 0.4113 - accuracy: 0.8541 - val_loss: 0.5989 - val_accuracy: 0.7824\n",
            "Epoch 479/500\n",
            "189/189 [==============================] - 71s 375ms/step - loss: 0.4130 - accuracy: 0.8471 - val_loss: 0.6019 - val_accuracy: 0.7774\n",
            "Epoch 480/500\n",
            "189/189 [==============================] - 69s 364ms/step - loss: 0.4085 - accuracy: 0.8494 - val_loss: 0.6017 - val_accuracy: 0.7794\n",
            "Epoch 481/500\n",
            "189/189 [==============================] - 68s 362ms/step - loss: 0.3965 - accuracy: 0.8561 - val_loss: 0.6016 - val_accuracy: 0.7824\n",
            "Epoch 482/500\n",
            "189/189 [==============================] - 67s 355ms/step - loss: 0.3974 - accuracy: 0.8562 - val_loss: 0.6070 - val_accuracy: 0.7814\n",
            "Epoch 483/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.4034 - accuracy: 0.8518 - val_loss: 0.6064 - val_accuracy: 0.7764\n",
            "Epoch 484/500\n",
            "189/189 [==============================] - 67s 357ms/step - loss: 0.3979 - accuracy: 0.8541 - val_loss: 0.6073 - val_accuracy: 0.7754\n",
            "Epoch 485/500\n",
            "189/189 [==============================] - 67s 355ms/step - loss: 0.3955 - accuracy: 0.8579 - val_loss: 0.6064 - val_accuracy: 0.7769\n",
            "Epoch 486/500\n",
            "189/189 [==============================] - 67s 354ms/step - loss: 0.3979 - accuracy: 0.8612 - val_loss: 0.6093 - val_accuracy: 0.7754\n",
            "Epoch 487/500\n",
            "189/189 [==============================] - 67s 355ms/step - loss: 0.3991 - accuracy: 0.8561 - val_loss: 0.6044 - val_accuracy: 0.7769\n",
            "Epoch 488/500\n",
            "189/189 [==============================] - 67s 356ms/step - loss: 0.3926 - accuracy: 0.8594 - val_loss: 0.6051 - val_accuracy: 0.7789\n",
            "Epoch 489/500\n",
            "189/189 [==============================] - 68s 357ms/step - loss: 0.3908 - accuracy: 0.8514 - val_loss: 0.6067 - val_accuracy: 0.7794\n",
            "Epoch 490/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.3863 - accuracy: 0.8627 - val_loss: 0.6008 - val_accuracy: 0.7804\n",
            "Epoch 491/500\n",
            "189/189 [==============================] - 68s 357ms/step - loss: 0.3831 - accuracy: 0.8619 - val_loss: 0.6018 - val_accuracy: 0.7819\n",
            "Epoch 492/500\n",
            "189/189 [==============================] - 68s 358ms/step - loss: 0.3854 - accuracy: 0.8589 - val_loss: 0.6035 - val_accuracy: 0.7769\n",
            "Epoch 493/500\n",
            "189/189 [==============================] - 66s 350ms/step - loss: 0.3868 - accuracy: 0.8559 - val_loss: 0.6024 - val_accuracy: 0.7809\n",
            "Epoch 494/500\n",
            "189/189 [==============================] - 67s 353ms/step - loss: 0.3837 - accuracy: 0.8650 - val_loss: 0.6020 - val_accuracy: 0.7859\n",
            "Epoch 495/500\n",
            "189/189 [==============================] - 66s 348ms/step - loss: 0.3872 - accuracy: 0.8629 - val_loss: 0.6078 - val_accuracy: 0.7814\n",
            "Epoch 496/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.3859 - accuracy: 0.8586 - val_loss: 0.6039 - val_accuracy: 0.7784\n",
            "Epoch 497/500\n",
            "189/189 [==============================] - 63s 336ms/step - loss: 0.3859 - accuracy: 0.8589 - val_loss: 0.6043 - val_accuracy: 0.7784\n",
            "Epoch 498/500\n",
            "189/189 [==============================] - 65s 346ms/step - loss: 0.3836 - accuracy: 0.8567 - val_loss: 0.6022 - val_accuracy: 0.7814\n",
            "Epoch 499/500\n",
            "189/189 [==============================] - 64s 341ms/step - loss: 0.3703 - accuracy: 0.8672 - val_loss: 0.6018 - val_accuracy: 0.7804\n",
            "Epoch 500/500\n",
            "189/189 [==============================] - 66s 347ms/step - loss: 0.3744 - accuracy: 0.8639 - val_loss: 0.5957 - val_accuracy: 0.7824\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32,3,padding=\"same\", activation=\"relu\", input_shape=(224,224,1)))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(32, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(64, 3, padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation=\"relu\"))\n",
        "model.add(Dense(5, activation=\"softmax\"))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "opt = Adam(lr=0.000001)\n",
        "model.compile(optimizer = opt , loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "history = model.fit(training_ds,\n",
        "          validation_data=val_ds,\n",
        "          epochs=500,\n",
        "          verbose=1\n",
        ")"
      ],
      "id": "1LfoxRTl8C3d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIS3u3Xq8C4w"
      },
      "outputs": [],
      "source": [
        "model.save('eccg_model.h5')"
      ],
      "id": "JIS3u3Xq8C4w"
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()"
      ],
      "metadata": {
        "id": "ErGUoX93002i",
        "outputId": "1c750d9c-00d0-45f7-f54c-99b1c2423c4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "ErGUoX93002i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/second sem'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LY0BbKu8C7e"
      },
      "outputs": [],
      "source": [
        "model.save_weights('ecg_model_weights.h5')"
      ],
      "id": "0LY0BbKu8C7e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Swf0M5h78C9L"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']"
      ],
      "id": "Swf0M5h78C9L"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "02qewJqYzHAq"
      },
      "id": "02qewJqYzHAq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybJkmxe68DAS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "outputId": "ab58f52f-9ab4-443c-e91f-ef38e8189c01"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x1080 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "epochs_range = range(500)\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "id": "ybJkmxe68DAS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model - 3**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "qGf3vhB_YkY2"
      },
      "id": "qGf3vhB_YkY2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3IhPY7OUf81A"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Dense, Convolution2D, Flatten, Dropout,MaxPooling2D,Conv2D\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import BatchNormalization\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "id": "3IhPY7OUf81A"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9-PlUH5frkQ"
      },
      "outputs": [],
      "source": [
        "def network(training_ds,val_ds):\n",
        "  \n",
        "  im_shape=(224,224,1)\n",
        "  inputs_cnn=Input(shape=(im_shape), name='inputs_cnn')\n",
        "  conv1_1=Conv2D(64, (6), activation='relu', input_shape=im_shape)(inputs_cnn)\n",
        "  conv1_1=BatchNormalization()(conv1_1)\n",
        "  pool1=MaxPooling2D(pool_size=(3), strides=(2), padding=\"same\")(conv1_1)\n",
        "\n",
        "  conv2_1=Conv2D(64, (3), activation='relu')(pool1)\n",
        "  conv2_1=BatchNormalization()(conv2_1)\n",
        "  pool2=MaxPooling2D(pool_size=(2), strides=(2), padding=\"same\")(conv2_1)\n",
        "\n",
        "  conv3_1=Conv2D(64, (3), activation='relu')(pool2)\n",
        "  conv3_1=BatchNormalization()(conv3_1)\n",
        "  pool3=MaxPooling2D(pool_size=(2), strides=(2), padding=\"same\")(conv3_1)\n",
        "\n",
        "  flatten=Flatten()(pool3)\n",
        "  dense_end1 = Dense(64, activation='relu')(flatten)\n",
        "  dense_end2 = Dense(32, activation='relu')(dense_end1)\n",
        "  main_output = Dense(5, activation='softmax', name='main_output')(dense_end2)\n",
        "\n",
        "\n",
        "  model = Model(inputs= inputs_cnn, outputs=main_output)\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "\n",
        "  callbacks = [EarlyStopping(monitor='val_loss', patience=8),\n",
        "            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "\n",
        "\n",
        "  history=model.fit(training_ds, epochs=40,callbacks=callbacks, batch_size=32,validation_data=val_ds)\n",
        "  model.load_weights('best_model.h5')\n",
        "  return(model,history)\n",
        "    "
      ],
      "id": "a9-PlUH5frkQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjZjY9oGg7TW",
        "outputId": "50f4be18-75a7-43ce-fc60-e7c89008828c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "189/189 [==============================] - 182s 962ms/step - loss: 5.9343 - accuracy: 0.8989 - val_loss: 135.8397 - val_accuracy: 0.0717\n",
            "Epoch 2/40\n",
            "189/189 [==============================] - 183s 967ms/step - loss: 5.7183 - accuracy: 0.8591 - val_loss: 1341.6213 - val_accuracy: 0.1389\n",
            "Epoch 3/40\n",
            "189/189 [==============================] - 181s 956ms/step - loss: 4.4294 - accuracy: 0.7498 - val_loss: 3.5840 - val_accuracy: 0.2136\n",
            "Epoch 4/40\n",
            "189/189 [==============================] - 186s 985ms/step - loss: 1.7333 - accuracy: 0.6964 - val_loss: 2.7176 - val_accuracy: 0.2719\n",
            "Epoch 5/40\n",
            "189/189 [==============================] - 215s 1s/step - loss: 1.8847 - accuracy: 0.6029 - val_loss: 2.4472 - val_accuracy: 0.2136\n",
            "Epoch 6/40\n",
            "189/189 [==============================] - 202s 1s/step - loss: 1.3482 - accuracy: 0.3103 - val_loss: 1.4473 - val_accuracy: 0.3695\n",
            "Epoch 7/40\n",
            "189/189 [==============================] - 182s 961ms/step - loss: 1.1862 - accuracy: 0.4314 - val_loss: 1.2449 - val_accuracy: 0.5030\n",
            "Epoch 8/40\n",
            "189/189 [==============================] - 179s 947ms/step - loss: 1.1543 - accuracy: 0.5105 - val_loss: 1.2658 - val_accuracy: 0.5005\n",
            "Epoch 9/40\n",
            "189/189 [==============================] - 180s 955ms/step - loss: 1.1359 - accuracy: 0.5051 - val_loss: 1.1622 - val_accuracy: 0.5020\n",
            "Epoch 10/40\n",
            "189/189 [==============================] - 180s 952ms/step - loss: 1.1140 - accuracy: 0.5073 - val_loss: 1.1551 - val_accuracy: 0.4910\n",
            "Epoch 11/40\n",
            "189/189 [==============================] - 178s 941ms/step - loss: 1.3237 - accuracy: 0.5181 - val_loss: 2.0795 - val_accuracy: 0.2913\n",
            "Epoch 12/40\n",
            "189/189 [==============================] - 178s 944ms/step - loss: 1.1588 - accuracy: 0.5100 - val_loss: 2.3725 - val_accuracy: 0.3660\n",
            "Epoch 13/40\n",
            "189/189 [==============================] - 178s 940ms/step - loss: 1.2596 - accuracy: 0.5802 - val_loss: 8.6687 - val_accuracy: 0.4308\n",
            "Epoch 14/40\n",
            "189/189 [==============================] - 180s 951ms/step - loss: 1.9543 - accuracy: 0.4960 - val_loss: 1.6795 - val_accuracy: 0.2684\n",
            "Epoch 15/40\n",
            "189/189 [==============================] - 178s 941ms/step - loss: 1.3574 - accuracy: 0.4084 - val_loss: 1.6805 - val_accuracy: 0.2669\n",
            "Epoch 16/40\n",
            "189/189 [==============================] - 179s 945ms/step - loss: 1.1849 - accuracy: 0.4920 - val_loss: 3.0299 - val_accuracy: 0.4512\n",
            "Epoch 17/40\n",
            "189/189 [==============================] - 178s 941ms/step - loss: 1.1307 - accuracy: 0.4874 - val_loss: 1.5213 - val_accuracy: 0.4935\n",
            "Epoch 18/40\n",
            "189/189 [==============================] - 178s 940ms/step - loss: 1.0775 - accuracy: 0.5096 - val_loss: 1.5546 - val_accuracy: 0.5045\n"
          ]
        }
      ],
      "source": [
        "model,history=network(training_ds=training_ds,val_ds=val_ds)"
      ],
      "id": "SjZjY9oGg7TW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model - 4 (Epochs incomplete)**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "dp_l9hjNZICF"
      },
      "id": "dp_l9hjNZICF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3cXmAqXg7V5"
      },
      "outputs": [],
      "source": [
        "IMAGE_SIZE = (224,224)"
      ],
      "id": "m3cXmAqXg7V5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e6UUMCYqfb5F"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, (3,3),strides = (1,1), input_shape = (224,224,1),kernel_initializer='glorot_uniform'))\n",
        "model.add(keras.layers.ELU())\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(64, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
        "model.add(keras.layers.ELU())\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides= (2,2)))\n",
        "\n",
        "model.add(Conv2D(128, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
        "model.add(keras.layers.ELU())\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(128, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
        "model.add(keras.layers.ELU())\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides= (2,2)))\n",
        "\n",
        "model.add(Conv2D(256, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
        "model.add(keras.layers.ELU())\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Conv2D(256, (3,3),strides = (1,1),kernel_initializer='glorot_uniform'))\n",
        "model.add(keras.layers.ELU())\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPool2D(pool_size=(2, 2), strides= (2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(2048))\n",
        "model.add(keras.layers.ELU())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "id": "e6UUMCYqfb5F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "v_5H-u33oH-5",
        "outputId": "0d785789-12c4-4895-9506-a281f81b4779"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/60\n",
            "189/189 [==============================] - 795s 4s/step - loss: 2.1166 - accuracy: 0.3430 - val_loss: 25.4381 - val_accuracy: 0.2684\n",
            "Epoch 2/60\n",
            "189/189 [==============================] - 856s 5s/step - loss: 2.0737 - accuracy: 0.2319 - val_loss: 2.3214 - val_accuracy: 0.2694\n",
            "Epoch 3/60\n",
            "189/189 [==============================] - 828s 4s/step - loss: 1.8972 - accuracy: 0.2500 - val_loss: 2.8270 - val_accuracy: 0.1728\n",
            "Epoch 4/60\n",
            " 74/189 [==========>...................] - ETA: 7:21 - loss: 1.8141 - accuracy: 0.2356"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-bcb65e129fe6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(training_ds,\n",
        "         validation_data=val_ds,\n",
        "         batch_size=32,\n",
        "         epochs=60,\n",
        "\n",
        ")"
      ],
      "id": "v_5H-u33oH-5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model - 5 (Epochs incomplete) -Pretrained-Vgg16**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "F0EOVoUPZPS2"
      },
      "id": "F0EOVoUPZPS2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZhnukXEfb7k",
        "outputId": "343c2888-b6dd-477f-9f03-784aeed40c9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 2s 0us/step\n",
            "553476096/553467096 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.layers import *\n",
        "\n",
        "\n",
        "img_size_target = 224\n",
        "img_input = Input(shape=(img_size_target, img_size_target, 1))\n",
        "img_conc = Concatenate()([img_input, img_input, img_input])  \n",
        "model = VGG16(input_tensor=img_conc)"
      ],
      "id": "HZhnukXEfb7k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkX1zFOPFgXG",
        "outputId": "451d833c-2ad9-44a3-a4e4-0501f84900a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"vgg16\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 224, 224, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 224, 224, 3)  0           ['input_7[0][0]',                \n",
            "                                                                  'input_7[0][0]',                \n",
            "                                                                  'input_7[0][0]']                \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['concatenate_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['block1_conv2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block2_conv1 (Conv2D)          (None, 112, 112, 12  73856       ['block1_pool[0][0]']            \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " block2_conv2 (Conv2D)          (None, 112, 112, 12  147584      ['block2_conv1[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " block2_pool (MaxPooling2D)     (None, 56, 56, 128)  0           ['block2_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv1 (Conv2D)          (None, 56, 56, 256)  295168      ['block2_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block3_conv2 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block3_conv3 (Conv2D)          (None, 56, 56, 256)  590080      ['block3_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block3_pool (MaxPooling2D)     (None, 28, 28, 256)  0           ['block3_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv1 (Conv2D)          (None, 28, 28, 512)  1180160     ['block3_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block4_conv2 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block4_conv3 (Conv2D)          (None, 28, 28, 512)  2359808     ['block4_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block4_pool (MaxPooling2D)     (None, 14, 14, 512)  0           ['block4_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv1 (Conv2D)          (None, 14, 14, 512)  2359808     ['block4_pool[0][0]']            \n",
            "                                                                                                  \n",
            " block5_conv2 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv1[0][0]']           \n",
            "                                                                                                  \n",
            " block5_conv3 (Conv2D)          (None, 14, 14, 512)  2359808     ['block5_conv2[0][0]']           \n",
            "                                                                                                  \n",
            " block5_pool (MaxPooling2D)     (None, 7, 7, 512)    0           ['block5_conv3[0][0]']           \n",
            "                                                                                                  \n",
            " global_average_pooling2d_5 (Gl  (None, 512)         0           ['block5_pool[0][0]']            \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,714,688\n",
            "Trainable params: 14,714,688\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import models\n",
        "\n",
        "num_classes = 5\n",
        "\n",
        "vgg = VGG16(include_top=False,pooling='avg',weights='imagenet',input_tensor=img_conc)\n",
        "\n",
        "vgg.summary()"
      ],
      "id": "WkX1zFOPFgXG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YthpM8BHG0D7",
        "outputId": "79e51204-1b19-4037-b911-3d370b83ff9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)           [(None, 224, 224, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 224, 224, 3)  0           ['input_7[0][0]',                \n",
            "                                                                  'input_7[0][0]',                \n",
            "                                                                  'input_7[0][0]']                \n",
            "                                                                                                  \n",
            " block1_conv1 (Conv2D)          (None, 224, 224, 64  1792        ['concatenate_1[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_conv2 (Conv2D)          (None, 224, 224, 64  36928       ['block1_conv1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block1_pool (MaxPooling2D)     (None, 112, 112, 64  0           ['block1_conv2[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 38,720\n",
            "Trainable params: 38,720\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Model\n",
        "\n",
        "layer_name = 'block1_pool'\n",
        "\n",
        "my_model= Model(inputs=vgg.input, outputs=vgg.get_layer(layer_name).output)\n",
        "my_model.summary()"
      ],
      "id": "YthpM8BHG0D7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVbN6CFUHEJa"
      },
      "outputs": [],
      "source": [
        "model = models.Sequential()\n",
        "\n",
        "model.add(my_model)\n",
        "\n",
        "from keras.layers import Dense,Conv2D,MaxPooling2D,BatchNormalization, GlobalAveragePooling2D,Input"
      ],
      "id": "xVbN6CFUHEJa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXKTi02PHWEJ",
        "outputId": "082811d5-1102-4537-d84b-faadda2235ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " model_6 (Functional)        (None, 112, 112, 64)      38720     \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 56, 56, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 28, 28, 256)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " global_average_pooling2d_6   (None, 256)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 424,773\n",
            "Trainable params: 385,925\n",
            "Non-trainable params: 38,848\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D((2,2),padding='same'))\n",
        "model.add(Conv2D(256,(3,3),activation='relu',padding='same'))\n",
        "model.add(MaxPooling2D((2,2),padding='same'))\n",
        "model.add(GlobalAveragePooling2D())\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(5,activation='softmax'))\n",
        "\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "model.summary()"
      ],
      "id": "FXKTi02PHWEJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "G_LgqQ-Vf6jU",
        "outputId": "2f1dc08f-57bc-4d92-e2c1-c9f39790448d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "189/189 [==============================] - 176s 930ms/step - loss: 1.6780 - accuracy: 0.2088 - val_loss: 6.1175 - val_accuracy: 0.2684\n",
            "Epoch 2/40\n",
            "189/189 [==============================] - 176s 930ms/step - loss: 1.6300 - accuracy: 0.1843 - val_loss: 232.2845 - val_accuracy: 0.0717\n",
            "Epoch 3/40\n",
            "189/189 [==============================] - 175s 929ms/step - loss: 1.6299 - accuracy: 0.1773 - val_loss: 1.7317 - val_accuracy: 0.2480\n",
            "Epoch 4/40\n",
            "189/189 [==============================] - 175s 928ms/step - loss: 1.6283 - accuracy: 0.1587 - val_loss: 1.6139 - val_accuracy: 0.2126\n",
            "Epoch 5/40\n",
            "189/189 [==============================] - 175s 927ms/step - loss: 1.6198 - accuracy: 0.1413 - val_loss: 1.5877 - val_accuracy: 0.3645\n",
            "Epoch 6/40\n",
            "189/189 [==============================] - 176s 933ms/step - loss: 1.6126 - accuracy: 0.1579 - val_loss: 1.5718 - val_accuracy: 0.2490\n",
            "Epoch 7/40\n",
            "189/189 [==============================] - 177s 935ms/step - loss: 1.6075 - accuracy: 0.1594 - val_loss: 1.5937 - val_accuracy: 0.2126\n",
            "Epoch 8/40\n",
            "189/189 [==============================] - 177s 938ms/step - loss: 1.6048 - accuracy: 0.1690 - val_loss: 1.5978 - val_accuracy: 0.2126\n",
            "Epoch 9/40\n",
            "189/189 [==============================] - 179s 945ms/step - loss: 1.5994 - accuracy: 0.1836 - val_loss: 1.5648 - val_accuracy: 0.2684\n",
            "Epoch 10/40\n",
            "189/189 [==============================] - 179s 949ms/step - loss: 1.5977 - accuracy: 0.1839 - val_loss: 1.5610 - val_accuracy: 0.2490\n",
            "Epoch 11/40\n",
            " 16/189 [=>............................] - ETA: 2:24 - loss: 1.5463 - accuracy: 0.0098"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-f4dff83cb692>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy',metrics = ['accuracy'])\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=8),\n",
        "            ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n",
        "\n",
        "history=model.fit(training_ds, epochs=40,callbacks=callbacks, batch_size=32,validation_data=val_ds)\n",
        "model.load_weights('best_model.h5')\n"
      ],
      "id": "G_LgqQ-Vf6jU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model - 6** \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "18TJfAkrZeRl"
      },
      "id": "18TJfAkrZeRl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8395e331"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization"
      ],
      "id": "8395e331"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "314544b0"
      },
      "outputs": [],
      "source": [
        "# img_rows, img_cols = 720, 576\n",
        "# input_shape = (img_rows, img_cols, 1)"
      ],
      "id": "314544b0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed845282"
      },
      "outputs": [],
      "source": [
        "cnn3 = Sequential()\n",
        "cnn3.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(224,224,1)))\n",
        "cnn3.add(BatchNormalization())\n",
        "\n",
        "cnn3.add(MaxPooling2D((2, 2)))\n",
        "cnn3.add(Dropout(0.25))\n",
        "\n",
        "cnn3.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "cnn3.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "cnn3.add(Dropout(0.25))\n",
        "\n",
        "cnn3.add(Conv2D(128, kernel_size=(2, 2), activation='relu'))\n",
        "cnn3.add(Dropout(0.4))\n",
        "\n",
        "cnn3.add(Flatten())\n",
        "\n",
        "cnn3.add(Dense(128, activation='relu'))\n",
        "cnn3.add(Dropout(0.3))\n",
        "cnn3.add(Dense(5, activation='softmax'))\n",
        "\n",
        "cnn3.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n"
      ],
      "id": "ed845282"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "043b9c4e",
        "outputId": "4cc0233f-77ee-4a7e-ae41-b8f2f482177b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/11\n",
            "189/189 [==============================] - 97s 513ms/step - loss: 59.4232 - accuracy: 0.4864 - val_loss: 1.6233 - val_accuracy: 0.1982\n",
            "Epoch 2/11\n",
            "189/189 [==============================] - 97s 514ms/step - loss: 1.5517 - accuracy: 0.2346 - val_loss: 1.5805 - val_accuracy: 0.2321\n",
            "Epoch 3/11\n",
            "189/189 [==============================] - 97s 513ms/step - loss: 1.3650 - accuracy: 0.3571 - val_loss: 1.4438 - val_accuracy: 0.3167\n",
            "Epoch 4/11\n",
            "189/189 [==============================] - 97s 515ms/step - loss: 1.2519 - accuracy: 0.4290 - val_loss: 1.4320 - val_accuracy: 0.2829\n",
            "Epoch 5/11\n",
            "189/189 [==============================] - 98s 518ms/step - loss: 4.9769 - accuracy: 0.6262 - val_loss: 1.6290 - val_accuracy: 0.2126\n",
            "Epoch 6/11\n",
            "189/189 [==============================] - 98s 517ms/step - loss: 3.2352 - accuracy: 0.7382 - val_loss: 1.9433 - val_accuracy: 0.3884\n",
            "Epoch 7/11\n",
            "189/189 [==============================] - 97s 513ms/step - loss: 1.1552 - accuracy: 0.5405 - val_loss: 3.4759 - val_accuracy: 0.5687\n",
            "Epoch 8/11\n",
            "189/189 [==============================] - 97s 513ms/step - loss: 1.1323 - accuracy: 0.6423 - val_loss: 1.4233 - val_accuracy: 0.4861\n",
            "Epoch 9/11\n",
            "189/189 [==============================] - 97s 515ms/step - loss: 0.8821 - accuracy: 0.7488 - val_loss: 1.1453 - val_accuracy: 0.6484\n",
            "Epoch 10/11\n",
            "189/189 [==============================] - 97s 515ms/step - loss: 0.6649 - accuracy: 0.8204 - val_loss: 1.4603 - val_accuracy: 0.5722\n",
            "Epoch 11/11\n",
            "189/189 [==============================] - 97s 516ms/step - loss: 3.6636 - accuracy: 0.7666 - val_loss: 1.8962 - val_accuracy: 0.3352\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efc09d2a110>"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn3.fit(training_ds,\n",
        "         validation_data=val_ds,\n",
        "         batch_size=32,\n",
        "         epochs=11,\n",
        "         verbose='auto',\n",
        ")"
      ],
      "id": "043b9c4e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b68a09d"
      },
      "outputs": [],
      "source": [
        "# cnn4 = Sequential()\n",
        "# cnn4.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "# cnn4.add(BatchNormalization())\n",
        "\n",
        "# cnn4.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "# cnn4.add(BatchNormalization())\n",
        "# cnn4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# cnn4.add(Dropout(0.25))\n",
        "\n",
        "# cnn4.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "# cnn4.add(BatchNormalization())\n",
        "# cnn4.add(Dropout(0.25))\n",
        "\n",
        "# cnn4.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "# cnn4.add(BatchNormalization())\n",
        "# cnn4.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# cnn4.add(Dropout(0.25))\n",
        "\n",
        "# cnn4.add(Flatten())\n",
        "\n",
        "# cnn4.add(Dense(512, activation='relu'))\n",
        "# cnn4.add(BatchNormalization())\n",
        "# cnn4.add(Dropout(0.5))\n",
        "\n",
        "# cnn4.add(Dense(128, activation='relu'))\n",
        "# cnn4.add(BatchNormalization())\n",
        "# cnn4.add(Dropout(0.5))\n",
        "\n",
        "# cnn4.add(Dense(5, activation='softmax'))\n",
        "\n",
        "# cnn4.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#               optimizer=keras.optimizers.Adam(),\n",
        "#               metrics=['accuracy'])"
      ],
      "id": "2b68a09d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fb23d9f"
      },
      "source": [
        "# Testing and Junkies"
      ],
      "id": "4fb23d9f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c39b4a18"
      },
      "source": [
        "### Do Not Run These unless testing something"
      ],
      "id": "c39b4a18"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8e8767c",
        "outputId": "860d6ea8-ab16-4f93-ad13-507dbc1e92e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anant\\jupyterBooks\\LectureNotebooks\\2022W\\AML_2404_LAB\\data1\\augmented\\abnormalHR\\cropped\\\n",
            "C:\\Users\\anant\\jupyterBooks\\LectureNotebooks\\2022W\\AML_2404_LAB\\data1\\augmented\\covid19\\cropped\\\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24084/1957532539.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'cropped'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\\\\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#reading the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mimgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#converting the image to grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "augmented_path = \"C:\\\\Users\\\\anant\\\\jupyterBooks\\\\LectureNotebooks\\\\2022W\\\\AML_2404_LAB\\\\data1\\\\augmented\"\n",
        "        \n",
        "\n",
        "for foldername in os.listdir(augmented_path): # retrieving the image files in the particular folder\n",
        "    \n",
        "    folder = augmented_path+\"\\\\\"+foldername\n",
        "    copy_path = augmented_path+'\\\\'+foldername+'\\\\cropped\\\\'\n",
        "    print(copy_path)\n",
        "    count = 0\n",
        "    \n",
        "    for filename in os.listdir(folder):\n",
        "    \n",
        "        if filename != 'cropped':\n",
        "            count += 1\n",
        "            image = cv2.imread(folder+\"\\\\\"+filename) #reading the images\n",
        "            imgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #converting the image to grayscale\n",
        "            \n",
        "            ret, thresh = cv2.threshold(imgray, 0, 1, 0) #finding image threshold\n",
        "            contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "            # finding all the contours using chain approx none, chain_approx_simple creating many no of contours\n",
        "            \n",
        "            contour_max = max(contours, key = cv2.contourArea) # finding the highest contour for cropping the image\n",
        "            \n",
        "            x,y,w,h = cv2.boundingRect(contour_max) # getting the co-ordinates\n",
        "            image = image[y:y+h, x:x+w] # cropping the frame\n",
        "            cv2.imwrite(copy_path + f'{foldername}_{count}.jpg', image)\n",
        "\n",
        "        else:\n",
        "            pass\n",
        "        "
      ],
      "id": "b8e8767c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b458b78"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2"
      ],
      "id": "3b458b78"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1d49a82d"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, img_to_array"
      ],
      "id": "1d49a82d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edbba8a1"
      },
      "source": [
        "## Testing Augmenting image code"
      ],
      "id": "edbba8a1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50f65a94",
        "outputId": "583b045f-1aa1-4ec1-9436-440be50d5902",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abnormalHR_0.jpg_0_840.jpeg', 'abnormalHR_0_cropped.jpeg.jpg', 'abnormalHR_124_cropped.jpeg.jpg', 'abnormalHR_14.jpg', 'abnormalHR_24.jpg_0_9181.jpeg', 'Screenshot 2022-03-28 222642.jpg']\n"
          ]
        }
      ],
      "source": [
        "path = \"C:\\\\Users\\\\anant\\\\jupyterBooks\\\\LectureNotebooks\\\\2022W\\\\AML_2404_LAB\\\\data\\\\test\"\n",
        "os.chdir(path)\n",
        "print(os.listdir(os.curdir))\n",
        "filename = \"abnormalHR_14\"\n",
        "\n",
        "img_batch_size = 8\n",
        "\n",
        "data_gen_args = dict(\n",
        "                     width_shift_range=0.1,\n",
        "                     height_shift_range=0.1,\n",
        "                     zoom_range=0.2,\n",
        "                     fill_mode='constant',\n",
        "                     cval=255\n",
        "                    )\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "\n",
        "img = cv2.imread(\"abnormalHR_14.jpg\")\n",
        "\n",
        "\n",
        "reshaped_np_arr = img.reshape((1,)+img.shape)\n",
        "count = 0\n",
        "\n",
        "#             generating the augmentation of images\n",
        "for batch in image_datagen.flow(\n",
        "    reshaped_np_arr,\n",
        "    batch_size=1,\n",
        "    save_to_dir=os.curdir,\n",
        "    save_prefix = filename,\n",
        "    save_format='jpeg',\n",
        "    seed=20\n",
        "):\n",
        "\n",
        "    count += 1\n",
        "    if count == img_batch_size:\n",
        "        break"
      ],
      "id": "50f65a94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d94496cf",
        "outputId": "bbbe1cc7-0c0f-4164-9ff8-81af8091b7d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abnormalHR_0.jpg_0_840.jpeg']\n",
            "<class 'tuple'>\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "path = \"C:\\\\Users\\\\anant\\\\jupyterBooks\\\\LectureNotebooks\\\\2022W\\\\AML_2404_LAB\\\\data\\\\test\"\n",
        "os.chdir(path)\n",
        "print(os.listdir(os.curdir))\n",
        "img = cv2.imread('abnormalHR_0.jpg_0_840.jpeg')\n",
        "\n",
        "imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "ret, thresh = cv2.threshold(imgray, 0, 1, 0)\n",
        "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "print(type(contours))\n",
        "print(len(contours))\n",
        "\n",
        "if len(contours) != 0:\n",
        "        \n",
        "    c = max(contours, key = cv2.contourArea)\n",
        "    contour_image = cv2.drawContours(img, contours, -1, (255,0,0), 3)\n",
        "    cv2.imshow(\"out\", contour_image)\n",
        "    cv2.waitKey(0)\n",
        "    x,y,w,h = cv2.boundingRect(c)\n",
        "        \n",
        "    rect = contour_image[y:y+h, x:x+w]\n",
        "    cv2.imshow(\"out\", rect)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "    "
      ],
      "id": "d94496cf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5467eb50",
        "outputId": "746d1dad-c1f1-457d-acb5-c2002f3cb99d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abnormalHR_0.jpg_0_840.jpeg', 'abnormalHR_0_cropped.jpeg.jpg', 'abnormalHR_124_cropped.jpeg.jpg', 'abnormalHR_24.jpg_0_9181.jpeg', 'Screenshot 2022-03-28 222642.jpg']\n",
            "[[[ -1  -1   1  -1]\n",
            "  [  2  -1  -1   0]\n",
            "  [  3   1  -1   0]\n",
            "  ...\n",
            "  [358 356  -1   0]\n",
            "  [359 357  -1   0]\n",
            "  [ -1 358  -1   0]]]\n",
            "360\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = \"C:\\\\Users\\\\anant\\\\jupyterBooks\\\\LectureNotebooks\\\\2022W\\\\AML_2404_LAB\\\\data\\\\test\"\n",
        "os.chdir(path)\n",
        "print(os.listdir(os.curdir))\n",
        "filename = \"abnormalHR_124_cropped.jpeg\"\n",
        "image = cv2.imread(\"abnormalHR_24.jpg_0_9181.jpeg\") #reading the images\n",
        "\n",
        "imgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) #converting the image to grayscale\n",
        "ret, thresh = cv2.threshold(imgray, 0, 1, 0) #finding image threshold\n",
        "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "# finding all the contours using chain approx none, chain_approx_simple creating many no of contours\n",
        "print(hierarchy)\n",
        "print(len(contours))\n",
        "\n",
        "contour_max = max(contours, key = cv2.contourArea) # finding the highest contour for cropping the image\n",
        "\n",
        "x,y,w,h = cv2.boundingRect(contour_max) # getting the co-ordinates\n",
        "\n",
        "image = image[y:y+h, x:x+w] # cropping the frame\n",
        "cv2.imwrite(f'{filename}.jpg', image)"
      ],
      "id": "5467eb50"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "650ee01d",
        "outputId": "3b6ac0ab-07fb-4976-de54-8c4545f660e1",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abnormalHR_0.jpg_0_840.jpeg']\n",
            "<class 'numpy.ndarray'>\n",
            "(101, 1, 2)\n"
          ]
        }
      ],
      "source": [
        "path = \"C:\\\\Users\\\\anant\\\\jupyterBooks\\\\LectureNotebooks\\\\2022W\\\\AML_2404_LAB\\\\data\\\\test\"\n",
        "os.chdir(path)\n",
        "print(os.listdir(os.curdir))\n",
        "img = cv2.imread('abnormalHR_0.jpg_0_840.jpeg', cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "# contours, _ = cv2.findContours(...) # Your call to find the contours using OpenCV 2.4.x\n",
        "blur = cv2.GaussianBlur(img,(5,5),0)\n",
        "ret, threshold = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "contrs, _ = cv2.findContours(threshold,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) # using threshold to get the contours\n",
        "\n",
        "contrs_list = list(contrs)\n",
        "contrs_list.remove(max(contrs_list, key = cv2.contourArea)) # removing the frame\n",
        "# again getting the largest frame that is the pulse frame\n",
        "\n",
        "c = max(contrs_list, key = cv2.contourArea)\n",
        "\n",
        "\n",
        "x,y,w,h = cv2.boundingRect(c) # getting the co-ordinates\n",
        "\n",
        "\n",
        "rect = img[y:y+h, x:x+w] # cropping the frame\n",
        "\n",
        "#                 cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),10) # drawing rectangle with the co-ordinates\n",
        "\n",
        "#                 gamma_corrected = gammaCorrection(rect,3) # gamma correction\n",
        "\n",
        "#                 (thresh, im_bw) = cv2.threshold(gamma_corrected, 50, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) # threshold is increased\n",
        "\n",
        "#                 im_bw_resize = cv2.resize(im_bw,(720, 576)) # resizing the image to 256\n",
        "# img = Image.fromarray(rect)\n",
        "\n",
        "\n",
        "cv2.imshow('image',rect)\n",
        "# cv2.drawContours(img, contrs, 3, (0,255,0), 3)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()\n",
        "\n",
        "#thrsh = cv2.adaptiveThreshold(img,255,cv2.ADAPTIVE_THRESH_MEAN_C,cv2.THRESH_BINARY,41,21) \n",
        "\n",
        "# canny_output = cv2.Canny(img, thrsh, thrsh * 2)\n",
        "# contours, _ = cv2.findContours(thrsh.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) # Your call to find the contours\n",
        "# print(contours)\n",
        "\n",
        "# # Draw contours\n",
        "# drawing = np.zeros((canny_output.shape[0], canny_output.shape[1], 3), dtype=np.uint8)\n",
        "# for i in range(len(contours)):\n",
        "#     color = (rng.randint(0,256), rng.randint(0,256), rng.randint(0,256))\n",
        "#     cv.drawContours(drawing, contours, i, color, 2, cv.LINE_8, hierarchy, 0)\n",
        "# # Show in a window\n",
        "# cv.imshow('Contours', drawing)\n",
        "\n"
      ],
      "id": "650ee01d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "185707d1"
      },
      "outputs": [],
      "source": [
        "idx = 2 # The index of the contour that surrounds your object\n",
        "mask = np.zeros_like(img) # Create mask where white is what we want, black otherwise\n",
        "cv2.drawContours(mask, contours, idx, 255, -1) # Draw filled contour in mask\n",
        "out = np.zeros_like(img) # Extract out the object and place into output image\n",
        "out[mask == 255] = img[mask == 255]\n",
        "\n",
        "# Show the output image\n",
        "cv2.imshow('Output', out)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "id": "185707d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f54791c5",
        "outputId": "8d477445-74f0-460a-a127-e0f211f69a2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abnormalHR_0.jpg_0_840.jpeg']\n"
          ]
        }
      ],
      "source": [
        "path = \"C:\\\\Users\\\\anant\\\\jupyterBooks\\\\LectureNotebooks\\\\2022W\\\\AML_2404_LAB\\\\data\\\\test\"\n",
        "os.chdir(path)\n",
        "print(os.listdir(os.curdir))\n",
        "img = cv2.imread('abnormalHR_0.jpg_0_840.jpeg') # Read in your image\n",
        "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "ret, mask = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU) \n",
        "\n",
        "kernel = np.ones((9,9), np.uint8)\n",
        "mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "# put mask into alpha channel of result\n",
        "result = img.copy()\n",
        "result = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
        "result[:, :, 3] = mask\n",
        "\n",
        "# save resulting masked image\n",
        "#cv2.imwrite('retina_masked.png', result)\n",
        "cv2.imshow('Output', result)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ],
      "id": "f54791c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ed620adf"
      },
      "outputs": [],
      "source": [
        "# PATH = \"data/covid19/\"\n",
        "\n",
        "\n",
        "# for filename in os.listdir(PATH):\n",
        "#     img = Image.open(os.path.join(PATH, filename)) # images are color images\n",
        "#     img = img.resize((1920,1080), Image.BICUBIC)\n",
        "#     img.save(Copy_to_path+filename) "
      ],
      "id": "ed620adf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93a0cf44"
      },
      "outputs": [],
      "source": [
        "\n",
        "# filename = 'data/covid19/Binder1_Page_001.jpg'\n",
        "\n",
        "# size = (720, 576)\n",
        "# count = 0\n",
        "# for filename in g\n",
        "# with Image.open(filename) as im:\n",
        "#     gray_img = ImageOps.grayscale(im)\n",
        "#     gray_img.save('data/covid19/processed/covid001'+'.jpeg')"
      ],
      "id": "93a0cf44"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89b2cf41"
      },
      "outputs": [],
      "source": [
        "# file_path = \"data/covid19/Binder1_Page_017\"\n",
        "# Copy_to_path=\"data/covid19/processed/\"\n",
        "\n",
        "# count = 0\n",
        "\n",
        "# for filename in glob.glob(f'{file_path}.jpg'):\n",
        "#     count += 1\n",
        "#     with Image.open(filename) as img:\n",
        "#         img = img.convert('L')\n",
        "#         img = img.filter(ImageFilter.SHARPEN)\n",
        "#         img = img.filter(ImageFilter.EDGE_ENHANCE)\n",
        "        \n",
        "#         #img = img.filter(ImageFilter.CONTOUR)    \n",
        "#         #img = img.filter(ImageFilter.EMBOSS)\n",
        "#         #img = img.filter(ImageFilter.EDGE_ENHANCE)\n",
        "#         image = np.array(img) # converting PIL image to numpy array\n",
        "        \n",
        "#         thrsh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 41, 21) \n",
        "\n",
        "#         contrs, _ = cv2.findContours(thrsh.copy(),cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE) # using threshold to get the contours\n",
        "#         contrs = list(contrs)\n",
        "        \n",
        "#         c = max(contrs, key = cv2.contourArea)\n",
        "        \n",
        "#         contrs.remove(max(contrs, key = cv2.contourArea)) # removing the frame\n",
        "\n",
        "#         c = max(contrs, key = cv2.contourArea) # again getting the largest frame that is the pulse frame\n",
        "\n",
        "#         x,y,w,h = cv2.boundingRect(c) # getting the co-ordinates\n",
        "\n",
        "\n",
        "#         rect = image[y:y+h, x:x+w] # cropping the frame\n",
        "\n",
        "#         cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),10) # drawing rectangle with the co-ordinates\n",
        "\n",
        "#         gamma_corrected = gammaCorrection(rect,3) # gamma correction\n",
        "\n",
        "#         (thresh, im_bw) = cv2.threshold(gamma_corrected, 50, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU) # threshold is increased\n",
        "        \n",
        "#         print(type(im_bw))\n",
        "#         processed_img = Image.fromarray(im_bw) #Converting the array to image\n",
        "#         processed_img.show()\n",
        "#         processed_img.save(Copy_to_path+f'/covid19_{count}.jpg', 'JPEG') \n"
      ],
      "id": "89b2cf41"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e882a52b"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "e882a52b"
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "c39b4a18"
      ],
      "machine_shape": "hm",
      "name": "ECG_imagedatase.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}